{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (8.3.27)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (4.66.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (6.1.0)\n",
      "Requirement already satisfied: torch!=2.4.0,>=1.8.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from ultralytics) (2.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from sympy==1.13.1->torch!=2.4.0,>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages (from jinja2->torch!=2.4.0,>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\gorme\\projects\\godseye\\apps\\backend\\dataset_processing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_working_directory = os.getcwd()\n",
    "\n",
    "print(\"Current working directory:\", current_working_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_model_path = current_working_directory + \"/models/yolov8n-pose.pt\"\n",
    "model_path = current_working_directory + \"/models/yolov8n.pt\"\n",
    "sample_video_path = current_working_directory + \"/resources/test_videos/_2RYnSFPD_U_0.avi\"\n",
    "sample_image_path = current_working_directory + \"/resources/private/'.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(pose_model_path)  \u001b[38;5;66;03m# build a new model from scratch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# model = YOLO(model_path)  # load a pretrained model (recommended for training)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py:176\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    149\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    150\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    152\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py:554\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\ultralytics\\engine\\predictor.py:169\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\ultralytics\\engine\\predictor.py:235\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# Warmup model\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone_warmup:\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarmup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriton\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimgsz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone_warmup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, [], \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:710\u001b[0m, in \u001b[0;36mAutoBackend.warmup\u001b[1;34m(self, imgsz)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwarmup\u001b[39m(\u001b[38;5;28mself\u001b[39m, imgsz\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m640\u001b[39m)):\n\u001b[0;32m    704\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Warm up the model by running one forward pass with a dummy input.\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \n\u001b[0;32m    707\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m        imgsz (tuple): The shape of the dummy input tensor in the format (batch_size, channels, height, width)\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m  \u001b[38;5;66;03m# noqa (import here so torchvision import time not recorded in postprocess time)\u001b[39;00m\n\u001b[0;32m    712\u001b[0m     warmup_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monnx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpb, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtriton, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(warmup_types) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtriton):\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torchvision\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torchvision\\models\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malexnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdensenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torchvision\\models\\convnext.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstochastic_depth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StochasticDepth\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_presets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageClassification\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torchvision\\ops\\__init__.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgiou_loss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generalized_box_iou_loss\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoolers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_align, PSRoIAlign\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_pool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_pool, PSRoIPool\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torchvision\\ops\\poolers.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m box_area\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roi_align\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# is not supported by ONNX tracing yet.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# that merges the levels to the right indices\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_onnx_merge_levels\u001b[39m(levels: Tensor, unmerged_results: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torchvision\\ops\\roi_align.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_compile_supported\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BroadcastingList2\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pair\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_dynamo\\__init__.py:39\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph_break_reasons, guard_failures, orig_code_map, reset_frame_count\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Register polyfill functions\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolyfills\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loader \u001b[38;5;28;01mas\u001b[39;00m _  \u001b[38;5;66;03m# usort: skip # noqa: F401\u001b[39;00m\n\u001b[0;32m     42\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_in_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massume_constant_result\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlookup_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     66\u001b[0m ]\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmanual_seed \u001b[38;5;129;01mis\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmanual_seed:\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_dynamo\\polyfills\\loader.py:22\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# See also the TYPE_CHECKING block in torch/_dynamo/polyfills/__init__.py\u001b[39;00m\n\u001b[0;32m     15\u001b[0m POLYFILLED_MODULE_NAMES: Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuiltins\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctools\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msys\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m POLYFILLED_MODULES: Tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModuleType\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubmodule\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolyfills\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubmodule\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPOLYFILLED_MODULE_NAMES\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Unregister the builtin functions from _builtin_function_ids to let them to be\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# dispatched with the appropriate VariableTracker type. Otherwise, they will be\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# dispatched with BuiltinVariable if present in _builtin_function_ids.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m polyfill_module \u001b[38;5;129;01min\u001b[39;00m POLYFILLED_MODULES:\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_dynamo\\polyfills\\loader.py:23\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# See also the TYPE_CHECKING block in torch/_dynamo/polyfills/__init__.py\u001b[39;00m\n\u001b[0;32m     15\u001b[0m POLYFILLED_MODULE_NAMES: Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuiltins\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctools\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msys\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m POLYFILLED_MODULES: Tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModuleType\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m---> 23\u001b[0m     \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubmodule\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolyfills\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m submodule \u001b[38;5;129;01min\u001b[39;00m POLYFILLED_MODULE_NAMES\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Unregister the builtin functions from _builtin_function_ids to let them to be\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# dispatched with the appropriate VariableTracker type. Otherwise, they will be\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# dispatched with BuiltinVariable if present in _builtin_function_ids.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m polyfill_module \u001b[38;5;129;01min\u001b[39;00m POLYFILLED_MODULES:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_dynamo\\polyfills\\builtins.py:24\u001b[0m\n\u001b[0;32m     13\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menumerate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m ]\n\u001b[0;32m     20\u001b[0m _T \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_T\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;129;43m@substitute_in_graph\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_constant_fold_through\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_dynamo\\decorators.py:312\u001b[0m, in \u001b[0;36msubstitute_in_graph.<locals>.wrapper\u001b[1;34m(traceable_fn)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(original_fn) \u001b[38;5;129;01min\u001b[39;00m id_dispatch_map:\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuplicate dispatch rule for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready registered in VariableBuilder\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms id dispatch map\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 312\u001b[0m rule_map: Dict[Any, Type[VariableTracker]] \u001b[38;5;241m=\u001b[39m \u001b[43mget_torch_obj_rule_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original_fn \u001b[38;5;129;01min\u001b[39;00m rule_map:\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuplicate object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with different rules: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    316\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPolyfilledFunctionVariable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrule_map[original_fn]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    317\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py:2860\u001b[0m, in \u001b[0;36mget_torch_obj_rule_map\u001b[1;34m()\u001b[0m\n\u001b[0;32m   2858\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m m\u001b[38;5;241m.\u001b[39mitems():  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   2859\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py#\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m k:\n\u001b[1;32m-> 2860\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mload_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2861\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2862\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _module_dir(torch) \u001b[38;5;241m+\u001b[39m k[\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch/\u001b[39m\u001b[38;5;124m\"\u001b[39m) :]\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py:2891\u001b[0m, in \u001b[0;36mload_object\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   2889\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2890\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid obj name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2891\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[43m_load_obj_from_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2892\u001b[0m     val \u001b[38;5;241m=\u001b[39m unwrap_if_wrapper(val)\n\u001b[0;32m   2893\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py:2875\u001b[0m, in \u001b[0;36m_load_obj_from_str\u001b[1;34m(fully_qualified_name)\u001b[0m\n\u001b[0;32m   2873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_obj_from_str\u001b[39m(fully_qualified_name):\n\u001b[0;32m   2874\u001b[0m     module, obj_name \u001b[38;5;241m=\u001b[39m fully_qualified_name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, maxsplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 2875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m, obj_name)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_higher_order_ops\\map.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DispatchKey\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dispatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m suspend_functionalization\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maot_autograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AOTConfig, create_joint\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     _has_potential_branch_input_alias,\n\u001b[0;32m      9\u001b[0m     _has_potential_branch_input_mutation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     UnsupportedAliasMutationException,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HigherOrderOperator\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py:128\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_aot_autograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraced_function_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     aot_dispatch_subclass,\n\u001b[0;32m    107\u001b[0m     create_functional_call,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m     fn_prepped_for_autograd,\n\u001b[0;32m    113\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_aot_autograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     _get_autocast_states,\n\u001b[0;32m    116\u001b[0m     _get_symint_hints,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m     strict_zip,\n\u001b[0;32m    127\u001b[0m )\n\u001b[1;32m--> 128\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartitioners\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_partition\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mzip\u001b[39m \u001b[38;5;241m=\u001b[39m strict_zip\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# This global counter increments every time we compile a graph with\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# AOTAutograd.  You can use this to correlate runtime error messages\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# with compile time (e.g., if you get an error at runtime saying\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# one counter is allocated per entire compiled block (but this block\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# may involve compiling multiple subgraphs; e.g., for forwards/backwards)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_functorch\\partitioners.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Dict, List, Optional, Set, Tuple, TYPE_CHECKING, Union\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minductor_prims\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpytree\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_inductor\\inductor_prims.py:93\u001b[0m\n\u001b[0;32m     81\u001b[0m force_stride_order \u001b[38;5;241m=\u001b[39m make_prim(\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minductor_force_stride_order(Tensor input, SymInt[] stride) -> Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     83\u001b[0m     eager_force_stride,\n\u001b[0;32m     84\u001b[0m     doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForce the stride order for input tensor. No-op if the input tensor already has the stride. Do a copy otherwise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     85\u001b[0m )\n\u001b[0;32m     86\u001b[0m _unsafe_index_put_ \u001b[38;5;241m=\u001b[39m make_prim(\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_unsafe_index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, indices, values, accumulate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m: torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39maten\u001b[38;5;241m.\u001b[39mindex_put_(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m     doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsafe index_put_ (doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt issue device asserts)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     92\u001b[0m )\n\u001b[1;32m---> 93\u001b[0m fma \u001b[38;5;241m=\u001b[39m \u001b[43mmake_prim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfma(Tensor a, Tensor b, Tensor c) -> Tensor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFused multiply add: fma(a, b, c) -> (a * b) + c without rounding after the multiplication\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_low_memory_max_pool2d_with_offsets_aten\u001b[39m(\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    102\u001b[0m     kernel_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m     ceil_mode,\n\u001b[0;32m    107\u001b[0m ):\n\u001b[0;32m    108\u001b[0m     vals, indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39maten\u001b[38;5;241m.\u001b[39mmax_pool2d_with_indices(\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;28mself\u001b[39m, kernel_size, stride, padding, dilation, ceil_mode\n\u001b[0;32m    110\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_inductor\\inductor_prims.py:31\u001b[0m, in \u001b[0;36mmake_prim\u001b[1;34m(schema, impl_aten, return_type, doc, tags)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeta\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _prims\u001b[38;5;241m.\u001b[39mTensorMeta(impl_aten(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_prims\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_prim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimpl_aten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimpl_aten\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_prims\\__init__.py:319\u001b[0m, in \u001b[0;36m_make_prim\u001b[1;34m(schema, return_type, meta, impl_aten, doc, tags, use_old_custom_ops_api, register_conj_neg_fallthrough)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39malias_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m arg\u001b[38;5;241m.\u001b[39malias_info\u001b[38;5;241m.\u001b[39mis_write:\n\u001b[0;32m    318\u001b[0m         mutates_args\u001b[38;5;241m.\u001b[39mappend(arg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 319\u001b[0m prim_def \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprims::\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_prim_impl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmutates_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmutates_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m prim_def\u001b[38;5;241m.\u001b[39mregister_fake(meta)\n\u001b[0;32m    327\u001b[0m \u001b[38;5;66;03m# all view ops get conj/neg fallthroughs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_library\\custom_ops.py:157\u001b[0m, in \u001b[0;36mcustom_op\u001b[1;34m(name, fn, mutates_args, device_types, schema)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_library\\custom_ops.py:138\u001b[0m, in \u001b[0;36mcustom_op.<locals>.inner\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m    135\u001b[0m     schema_str \u001b[38;5;241m=\u001b[39m schema\n\u001b[0;32m    137\u001b[0m namespace, opname \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 138\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mCustomOpDef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# Check that schema's alias annotations match those of `mutates_args`.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     expected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_library\\custom_ops.py:186\u001b[0m, in \u001b[0;36mCustomOpDef.__init__\u001b[1;34m(self, namespace, name, schema, fn)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vmap_fn: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lib \u001b[38;5;241m=\u001b[39m get_library_allowing_overwrite(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_namespace, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n\u001b[1;32m--> 186\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_to_dispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disabled_kernel: Set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    188\u001b[0m OPDEFS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qualname] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_library\\custom_ops.py:616\u001b[0m, in \u001b[0;36mCustomOpDef._register_to_dispatcher\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    609\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was no fake impl registered for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    610\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is necessary for torch.compile/export/fx tracing to work. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    611\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.register_fake` to add an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfake impl.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m         )\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_abstract_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 616\u001b[0m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m autograd_impl \u001b[38;5;241m=\u001b[39m autograd\u001b[38;5;241m.\u001b[39mmake_autograd_impl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opoverload, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    619\u001b[0m lib\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, autograd_impl, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutograd\u001b[39m\u001b[38;5;124m\"\u001b[39m, with_keyset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\library.py:184\u001b[0m, in \u001b[0;36mLibrary._register_fake\u001b[1;34m(self, op_name, fn, _stacklevel)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     func_to_register \u001b[38;5;241m=\u001b[39m fn\n\u001b[1;32m--> 184\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_to_register\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registration_handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\_library\\fake_impl.py:61\u001b[0m, in \u001b[0;36mFakeImplHolder.register\u001b[1;34m(self, func, source)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     ns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlib \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFRAGMENT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: TOR901\u001b[39;00m\n\u001b[0;32m     62\u001b[0m meta_kernel \u001b[38;5;241m=\u001b[39m construct_meta_kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname, meta_kernel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gorme\\projects\\godseye\\.venv\\lib\\site-packages\\torch\\library.py:85\u001b[0m, in \u001b[0;36mLibrary.__init__\u001b[1;34m(self, ns, kind, dispatch_key)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ns \u001b[38;5;129;01min\u001b[39;00m _reserved_namespaces \u001b[38;5;129;01mand\u001b[39;00m (kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFRAGMENT\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     81\u001b[0m         ns,\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is a reserved namespace. Please try creating a library with another name.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     83\u001b[0m     )\n\u001b[1;32m---> 85\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     86\u001b[0m filename, lineno \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mfilename, frame\u001b[38;5;241m.\u001b[39mlineno\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm: Optional[Any] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dispatch_library(\n\u001b[0;32m     88\u001b[0m     kind, ns, dispatch_key, filename, lineno\n\u001b[0;32m     89\u001b[0m )\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\traceback.py:379\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    376\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    377\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 379\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "\n",
    "model = YOLO(pose_model_path)  # build a new model from scratch\n",
    "# model = YOLO(model_path)  # load a pretrained model (recommended for training)\n",
    "results = model(source=sample_video_path, show=True, conf=0.3, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\gorme\\projects\\godseye\\apps\\backend\\dataset_processing\\resources\\private\\'.jpg: 480x640 2 persons, 167.4ms\n",
      "Speed: 6.6ms preprocess, 167.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "model = YOLO(pose_model_path)  # build a new model from scratch\n",
    "# model = YOLO(model_path)  # load a pretrained model (recommended for training)\n",
    "\n",
    "results = model(source=sample_image_path, show=True, conf=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[117, 121, 126],\n",
       "         [117, 121, 126],\n",
       "         [117, 121, 126],\n",
       "         ...,\n",
       "         [143, 145, 145],\n",
       "         [145, 147, 147],\n",
       "         [146, 148, 148]],\n",
       " \n",
       "        [[117, 121, 126],\n",
       "         [117, 121, 126],\n",
       "         [117, 121, 126],\n",
       "         ...,\n",
       "         [144, 146, 146],\n",
       "         [145, 147, 147],\n",
       "         [147, 149, 149]],\n",
       " \n",
       "        [[117, 121, 126],\n",
       "         [117, 121, 126],\n",
       "         [117, 121, 126],\n",
       "         ...,\n",
       "         [145, 147, 147],\n",
       "         [147, 149, 149],\n",
       "         [147, 149, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 90,  90,  90],\n",
       "         [ 89,  89,  89],\n",
       "         [ 86,  86,  86],\n",
       "         ...,\n",
       "         [ 58,  58,  52],\n",
       "         [ 51,  51,  45],\n",
       "         [ 44,  44,  38]],\n",
       " \n",
       "        [[ 89,  89,  89],\n",
       "         [ 87,  87,  87],\n",
       "         [ 84,  84,  84],\n",
       "         ...,\n",
       "         [ 65,  65,  59],\n",
       "         [ 59,  59,  53],\n",
       "         [ 54,  54,  48]],\n",
       " \n",
       "        [[ 88,  88,  88],\n",
       "         [ 86,  86,  86],\n",
       "         [ 84,  84,  84],\n",
       "         ...,\n",
       "         [ 69,  69,  63],\n",
       "         [ 66,  66,  60],\n",
       "         [ 63,  63,  57]]], dtype=uint8)\n",
       " orig_shape: (3024, 4032)\n",
       " path: \"c:\\\\Users\\\\gorme\\\\projects\\\\godseye\\\\apps\\\\backend\\\\dataset_processing\\\\resources\\\\private\\\\'.jpg\"\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\gorme\\\\projects\\\\godseye\\\\apps\\\\backend\\\\Pose-Estimation-Ultralytics\\\\runs\\\\pose\\\\predict20'\n",
       " speed: {'preprocess': 6.603240966796875, 'inference': 167.42801666259766, 'postprocess': 2.0189285278320312}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0., 0.])\n",
      "conf: tensor([0.9088, 0.8906])\n",
      "data: tensor([[1.3730e+03, 8.6000e+02, 2.0000e+03, 2.6010e+03, 9.0881e-01, 0.0000e+00],\n",
      "        [2.2030e+03, 8.8700e+02, 2.7130e+03, 2.6150e+03, 8.9061e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (3024, 4032)\n",
      "shape: torch.Size([2, 6])\n",
      "xywh: tensor([[1686.5000, 1730.5000,  627.0000, 1741.0000],\n",
      "        [2458.0000, 1751.0000,  510.0000, 1728.0000]])\n",
      "xywhn: tensor([[0.4183, 0.5723, 0.1555, 0.5757],\n",
      "        [0.6096, 0.5790, 0.1265, 0.5714]])\n",
      "xyxy: tensor([[1373.,  860., 2000., 2601.],\n",
      "        [2203.,  887., 2713., 2615.]])\n",
      "xyxyn: tensor([[0.3405, 0.2844, 0.4960, 0.8601],\n",
      "        [0.5464, 0.2933, 0.6729, 0.8647]])\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.3730e+03, 8.6000e+02, 2.0000e+03, 2.6010e+03, 9.0881e-01, 0.0000e+00],\n",
       "        [2.2030e+03, 8.8700e+02, 2.7130e+03, 2.6150e+03, 8.9061e-01, 0.0000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for result in results:\n",
    "   boxes = result.boxes  # Boxes object for bbox outputs\n",
    "   masks = result.masks  # Masks object for segmenation masks outputs\n",
    "   probs = result.probs  # Class probabilities\n",
    "   print(boxes)\n",
    "   print(masks)\n",
    "   print(probs)\n",
    "\n",
    "\n",
    "boxes = results[0].boxes\n",
    "box = boxes[0]  # returns one box\n",
    "box.xyxy\n",
    "boxes.xyxy  # box with xyxy format, (N, 4)\n",
    "boxes.xywh  # box with xywh format, (N, 4)\n",
    "boxes.xyxyn  # box with xyxy format but normalized, (N, 4)\n",
    "boxes.xywhn  # box with xywh format but normalized, (N, 4)\n",
    "boxes.conf  # confidence score, (N, 1)\n",
    "boxes.cls  # cls, (N, 1)\n",
    "boxes.data  # raw bboxes tensor, (N, 6) or boxes.boxes ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  'result.tojson()' is deprecated, replace with 'result.to_json()'.\n",
      "[\n",
      "  {\n",
      "    \"name\": \"person\",\n",
      "    \"class\": 0,\n",
      "    \"confidence\": 0.90881,\n",
      "    \"box\": {\n",
      "      \"x1\": 0.34053,\n",
      "      \"y1\": 0.28439,\n",
      "      \"x2\": 0.49603,\n",
      "      \"y2\": 0.86012\n",
      "    },\n",
      "    \"keypoints\": {\n",
      "      \"x\": [\n",
      "        0.0,\n",
      "        0.0,\n",
      "        0.0,\n",
      "        0.3927899897098541,\n",
      "        0.4289500117301941,\n",
      "        0.3716900050640106,\n",
      "        0.44940000772476196,\n",
      "        0.3576599955558777,\n",
      "        0.47839000821113586,\n",
      "        0.37654000520706177,\n",
      "        0.47979000210762024,\n",
      "        0.3970299959182739,\n",
      "        0.4491400122642517,\n",
      "        0.3934600055217743,\n",
      "        0.45076999068260193,\n",
      "        0.4020000100135803,\n",
      "        0.46250998973846436\n",
      "      ],\n",
      "      \"y\": [\n",
      "        0.0,\n",
      "        0.0,\n",
      "        0.0,\n",
      "        0.3305000066757202,\n",
      "        0.3266400098800659,\n",
      "        0.3903999924659729,\n",
      "        0.3827899992465973,\n",
      "        0.46597999334335327,\n",
      "        0.4520699977874756,\n",
      "        0.5097799897193909,\n",
      "        0.5180500149726868,\n",
      "        0.5533599853515625,\n",
      "        0.5492200255393982,\n",
      "        0.6911699771881104,\n",
      "        0.6780800223350525,\n",
      "        0.8173400163650513,\n",
      "        0.8043400049209595\n",
      "      ],\n",
      "      \"visible\": [\n",
      "        0.2243800014257431,\n",
      "        0.05852000042796135,\n",
      "        0.10452000051736832,\n",
      "        0.5173299908638,\n",
      "        0.6621400117874146,\n",
      "        0.9824600219726562,\n",
      "        0.988510012626648,\n",
      "        0.9313399791717529,\n",
      "        0.9684100151062012,\n",
      "        0.8308299779891968,\n",
      "        0.903410017490387,\n",
      "        0.9975100159645081,\n",
      "        0.9981899857521057,\n",
      "        0.9945799708366394,\n",
      "        0.9964100122451782,\n",
      "        0.9724599719047546,\n",
      "        0.9799500107765198\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"person\",\n",
      "    \"class\": 0,\n",
      "    \"confidence\": 0.89061,\n",
      "    \"box\": {\n",
      "      \"x1\": 0.54638,\n",
      "      \"y1\": 0.29332,\n",
      "      \"x2\": 0.67287,\n",
      "      \"y2\": 0.86475\n",
      "    },\n",
      "    \"keypoints\": {\n",
      "      \"x\": [\n",
      "        0.0,\n",
      "        0.0,\n",
      "        0.0,\n",
      "        0.5922499895095825,\n",
      "        0.0,\n",
      "        0.5860900282859802,\n",
      "        0.6447799801826477,\n",
      "        0.5736799836158752,\n",
      "        0.6604800224304199,\n",
      "        0.5618699789047241,\n",
      "        0.6469399929046631,\n",
      "        0.5954399704933167,\n",
      "        0.63714998960495,\n",
      "        0.5806800127029419,\n",
      "        0.6386299729347229,\n",
      "        0.5793799757957458,\n",
      "        0.6483299732208252\n",
      "      ],\n",
      "      \"y\": [\n",
      "        0.0,\n",
      "        0.0,\n",
      "        0.0,\n",
      "        0.34233999252319336,\n",
      "        0.0,\n",
      "        0.4051100015640259,\n",
      "        0.40057000517845154,\n",
      "        0.4913800060749054,\n",
      "        0.4858100116252899,\n",
      "        0.560670018196106,\n",
      "        0.5418599843978882,\n",
      "        0.5684800148010254,\n",
      "        0.5674700140953064,\n",
      "        0.6942600011825562,\n",
      "        0.6983000040054321,\n",
      "        0.820930004119873,\n",
      "        0.8266000151634216\n",
      "      ],\n",
      "      \"visible\": [\n",
      "        0.2869099974632263,\n",
      "        0.17324000597000122,\n",
      "        0.05923999845981598,\n",
      "        0.743340015411377,\n",
      "        0.36302000284194946,\n",
      "        0.9905800223350525,\n",
      "        0.9848099946975708,\n",
      "        0.9749900102615356,\n",
      "        0.9419500231742859,\n",
      "        0.930620014667511,\n",
      "        0.881879985332489,\n",
      "        0.9988099932670593,\n",
      "        0.998420000076294,\n",
      "        0.9976699948310852,\n",
      "        0.9971699714660645,\n",
      "        0.9866799712181091,\n",
      "        0.9858599901199341\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your results object is named 'results'\n",
    "for r in results:\n",
    "    print(r.tojson(normalize=True))\n",
    "    r.save_crop(save_dir='sample')\n",
    "    image_array = r.plot(conf=True, boxes=True)\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(image_array)\n",
    "    plt.axis('off')  # Turn off axis numbers and ticks\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stream it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "from ultralytics import YOLO\n",
    "\n",
    "# load the model\n",
    "model = YOLO(pose_model_path)\n",
    "\n",
    "# open the video file path\n",
    "# video_path = \"./resources/pose-img.jpg\"\n",
    "\n",
    "video_path = 0\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "def stream():\n",
    "    # loop through the video frames\n",
    "    while cap.isOpened():\n",
    "        #read a frame\n",
    "        success, frame = cap.read()\n",
    "        \n",
    "        if success:\n",
    "            results = model(frame, save=True)\n",
    "            \n",
    "            #visualize the results\n",
    "            annotated_frame = results[0].plot()\n",
    "            \n",
    "            cv2.imshow(\"Output\", annotated_frame)\n",
    "            \n",
    "            #break the loop on key press q\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "            \n",
    "        else:\n",
    "            #the video end is reached\n",
    "            break\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 194.9ms\n",
      "Speed: 27.5ms preprocess, 194.9ms inference, 7.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 85.8ms\n",
      "Speed: 5.0ms preprocess, 85.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 78.0ms\n",
      "Speed: 1.2ms preprocess, 78.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 80.1ms\n",
      "Speed: 1.0ms preprocess, 80.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 84.5ms\n",
      "Speed: 2.2ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 83.1ms\n",
      "Speed: 2.0ms preprocess, 83.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 106.0ms\n",
      "Speed: 2.0ms preprocess, 106.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 153.4ms\n",
      "Speed: 3.0ms preprocess, 153.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 154.7ms\n",
      "Speed: 5.0ms preprocess, 154.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 91.2ms\n",
      "Speed: 1.0ms preprocess, 91.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 132.1ms\n",
      "Speed: 3.0ms preprocess, 132.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 127.6ms\n",
      "Speed: 3.3ms preprocess, 127.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 89.1ms\n",
      "Speed: 1.3ms preprocess, 89.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 146.5ms\n",
      "Speed: 4.0ms preprocess, 146.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 106.9ms\n",
      "Speed: 1.0ms preprocess, 106.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 91.6ms\n",
      "Speed: 3.6ms preprocess, 91.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 115.9ms\n",
      "Speed: 1.0ms preprocess, 115.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 113.8ms\n",
      "Speed: 2.8ms preprocess, 113.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 159.6ms\n",
      "Speed: 2.3ms preprocess, 159.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 82.8ms\n",
      "Speed: 1.0ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 131.2ms\n",
      "Speed: 1.9ms preprocess, 131.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 119.6ms\n",
      "Speed: 4.0ms preprocess, 119.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 149.1ms\n",
      "Speed: 2.0ms preprocess, 149.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 172.1ms\n",
      "Speed: 2.0ms preprocess, 172.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 214.7ms\n",
      "Speed: 2.0ms preprocess, 214.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 230.7ms\n",
      "Speed: 4.0ms preprocess, 230.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 104.8ms\n",
      "Speed: 1.6ms preprocess, 104.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 107.8ms\n",
      "Speed: 2.4ms preprocess, 107.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 97.0ms\n",
      "Speed: 2.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 90.4ms\n",
      "Speed: 1.4ms preprocess, 90.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 128.1ms\n",
      "Speed: 2.1ms preprocess, 128.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 144.6ms\n",
      "Speed: 4.0ms preprocess, 144.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 172.4ms\n",
      "Speed: 3.0ms preprocess, 172.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 144.6ms\n",
      "Speed: 3.0ms preprocess, 144.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 94.8ms\n",
      "Speed: 3.1ms preprocess, 94.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 139.6ms\n",
      "Speed: 3.0ms preprocess, 139.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 100.4ms\n",
      "Speed: 2.0ms preprocess, 100.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 145.0ms\n",
      "Speed: 1.0ms preprocess, 145.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 153.7ms\n",
      "Speed: 3.7ms preprocess, 153.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 154.8ms\n",
      "Speed: 2.0ms preprocess, 154.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 110.4ms\n",
      "Speed: 1.6ms preprocess, 110.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 134.8ms\n",
      "Speed: 2.3ms preprocess, 134.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 152.2ms\n",
      "Speed: 3.1ms preprocess, 152.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 120.8ms\n",
      "Speed: 3.0ms preprocess, 120.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 97.4ms\n",
      "Speed: 1.1ms preprocess, 97.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 121.5ms\n",
      "Speed: 1.0ms preprocess, 121.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 132.4ms\n",
      "Speed: 3.0ms preprocess, 132.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 97.3ms\n",
      "Speed: 1.0ms preprocess, 97.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 107.6ms\n",
      "Speed: 1.0ms preprocess, 107.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 179.0ms\n",
      "Speed: 3.0ms preprocess, 179.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 157.1ms\n",
      "Speed: 4.0ms preprocess, 157.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 127.1ms\n",
      "Speed: 3.0ms preprocess, 127.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 92.7ms\n",
      "Speed: 1.4ms preprocess, 92.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 101.4ms\n",
      "Speed: 1.0ms preprocess, 101.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 115.1ms\n",
      "Speed: 1.0ms preprocess, 115.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 182.9ms\n",
      "Speed: 2.5ms preprocess, 182.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 191.3ms\n",
      "Speed: 3.1ms preprocess, 191.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 196.3ms\n",
      "Speed: 3.5ms preprocess, 196.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 156.7ms\n",
      "Speed: 3.0ms preprocess, 156.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 182.6ms\n",
      "Speed: 2.0ms preprocess, 182.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 167.7ms\n",
      "Speed: 3.0ms preprocess, 167.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 184.1ms\n",
      "Speed: 3.0ms preprocess, 184.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 186.4ms\n",
      "Speed: 2.0ms preprocess, 186.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 176.9ms\n",
      "Speed: 2.0ms preprocess, 176.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 189.6ms\n",
      "Speed: 3.0ms preprocess, 189.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 154.9ms\n",
      "Speed: 3.6ms preprocess, 154.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 178.3ms\n",
      "Speed: 2.0ms preprocess, 178.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 123.4ms\n",
      "Speed: 2.0ms preprocess, 123.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 156.2ms\n",
      "Speed: 2.5ms preprocess, 156.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 137.8ms\n",
      "Speed: 2.5ms preprocess, 137.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 134.9ms\n",
      "Speed: 2.1ms preprocess, 134.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 138.6ms\n",
      "Speed: 3.0ms preprocess, 138.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 171.4ms\n",
      "Speed: 2.4ms preprocess, 171.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 174.1ms\n",
      "Speed: 2.0ms preprocess, 174.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 169.3ms\n",
      "Speed: 3.0ms preprocess, 169.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 182.7ms\n",
      "Speed: 2.0ms preprocess, 182.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 184.2ms\n",
      "Speed: 3.0ms preprocess, 184.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 173.2ms\n",
      "Speed: 3.5ms preprocess, 173.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 128.9ms\n",
      "Speed: 3.0ms preprocess, 128.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 152.2ms\n",
      "Speed: 1.3ms preprocess, 152.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 178.4ms\n",
      "Speed: 4.0ms preprocess, 178.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 173.0ms\n",
      "Speed: 3.0ms preprocess, 173.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 157.4ms\n",
      "Speed: 2.0ms preprocess, 157.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 165.2ms\n",
      "Speed: 2.3ms preprocess, 165.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 115.2ms\n",
      "Speed: 2.0ms preprocess, 115.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 102.5ms\n",
      "Speed: 2.1ms preprocess, 102.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 140.5ms\n",
      "Speed: 2.0ms preprocess, 140.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 83.4ms\n",
      "Speed: 2.2ms preprocess, 83.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 142.5ms\n",
      "Speed: 3.0ms preprocess, 142.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 85.7ms\n",
      "Speed: 2.0ms preprocess, 85.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 92.9ms\n",
      "Speed: 4.3ms preprocess, 92.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 88.4ms\n",
      "Speed: 1.7ms preprocess, 88.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 139.9ms\n",
      "Speed: 2.0ms preprocess, 139.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 116.5ms\n",
      "Speed: 3.0ms preprocess, 116.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 123.8ms\n",
      "Speed: 4.3ms preprocess, 123.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 127.5ms\n",
      "Speed: 3.0ms preprocess, 127.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 109.6ms\n",
      "Speed: 2.0ms preprocess, 109.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 93.5ms\n",
      "Speed: 2.0ms preprocess, 93.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 81.8ms\n",
      "Speed: 2.0ms preprocess, 81.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 98.4ms\n",
      "Speed: 2.0ms preprocess, 98.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 85.0ms\n",
      "Speed: 1.0ms preprocess, 85.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 84.4ms\n",
      "Speed: 2.0ms preprocess, 84.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 86.4ms\n",
      "Speed: 2.0ms preprocess, 86.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 85.4ms\n",
      "Speed: 1.0ms preprocess, 85.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 91.6ms\n",
      "Speed: 2.0ms preprocess, 91.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 129.4ms\n",
      "Speed: 3.0ms preprocess, 129.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 95.6ms\n",
      "Speed: 3.1ms preprocess, 95.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 125.6ms\n",
      "Speed: 0.9ms preprocess, 125.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 123.5ms\n",
      "Speed: 1.0ms preprocess, 123.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 122.1ms\n",
      "Speed: 2.6ms preprocess, 122.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 156.4ms\n",
      "Speed: 3.0ms preprocess, 156.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 176.6ms\n",
      "Speed: 3.5ms preprocess, 176.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 176.8ms\n",
      "Speed: 2.0ms preprocess, 176.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 124.0ms\n",
      "Speed: 2.7ms preprocess, 124.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 86.8ms\n",
      "Speed: 1.3ms preprocess, 86.8ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 86.2ms\n",
      "Speed: 1.4ms preprocess, 86.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 97.6ms\n",
      "Speed: 2.0ms preprocess, 97.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 89.6ms\n",
      "Speed: 2.0ms preprocess, 89.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 94.8ms\n",
      "Speed: 3.0ms preprocess, 94.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 174.9ms\n",
      "Speed: 3.0ms preprocess, 174.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 142.5ms\n",
      "Speed: 2.0ms preprocess, 142.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 127.1ms\n",
      "Speed: 2.0ms preprocess, 127.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 161.0ms\n",
      "Speed: 2.0ms preprocess, 161.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 129.5ms\n",
      "Speed: 2.0ms preprocess, 129.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 129.6ms\n",
      "Speed: 3.0ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 138.9ms\n",
      "Speed: 2.0ms preprocess, 138.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 150.1ms\n",
      "Speed: 3.0ms preprocess, 150.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 158.9ms\n",
      "Speed: 3.3ms preprocess, 158.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 159.0ms\n",
      "Speed: 2.0ms preprocess, 159.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 140.1ms\n",
      "Speed: 2.2ms preprocess, 140.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 133.5ms\n",
      "Speed: 3.0ms preprocess, 133.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 126.6ms\n",
      "Speed: 2.0ms preprocess, 126.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 128.8ms\n",
      "Speed: 2.0ms preprocess, 128.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 133.8ms\n",
      "Speed: 3.0ms preprocess, 133.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 129.9ms\n",
      "Speed: 2.0ms preprocess, 129.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 110.5ms\n",
      "Speed: 3.0ms preprocess, 110.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 122.4ms\n",
      "Speed: 2.3ms preprocess, 122.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 158.1ms\n",
      "Speed: 2.0ms preprocess, 158.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 88.9ms\n",
      "Speed: 1.5ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 112.4ms\n",
      "Speed: 1.0ms preprocess, 112.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 87.4ms\n",
      "Speed: 2.0ms preprocess, 87.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 97.3ms\n",
      "Speed: 3.2ms preprocess, 97.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 85.5ms\n",
      "Speed: 1.2ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 88.6ms\n",
      "Speed: 3.0ms preprocess, 88.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 90.2ms\n",
      "Speed: 2.0ms preprocess, 90.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 156.2ms\n",
      "Speed: 3.0ms preprocess, 156.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 117.1ms\n",
      "Speed: 3.0ms preprocess, 117.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 125.2ms\n",
      "Speed: 2.6ms preprocess, 125.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 117.3ms\n",
      "Speed: 2.0ms preprocess, 117.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 168.3ms\n",
      "Speed: 3.0ms preprocess, 168.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 121.0ms\n",
      "Speed: 2.1ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 160.1ms\n",
      "Speed: 3.5ms preprocess, 160.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 91.7ms\n",
      "Speed: 1.0ms preprocess, 91.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 138.0ms\n",
      "Speed: 2.6ms preprocess, 138.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 153.7ms\n",
      "Speed: 2.0ms preprocess, 153.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 145.6ms\n",
      "Speed: 3.0ms preprocess, 145.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 97.5ms\n",
      "Speed: 2.0ms preprocess, 97.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 142.8ms\n",
      "Speed: 3.0ms preprocess, 142.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 83.6ms\n",
      "Speed: 1.8ms preprocess, 83.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 106.2ms\n",
      "Speed: 2.0ms preprocess, 106.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 133.3ms\n",
      "Speed: 2.0ms preprocess, 133.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 104.7ms\n",
      "Speed: 1.0ms preprocess, 104.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 183.5ms\n",
      "Speed: 3.0ms preprocess, 183.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 187.4ms\n",
      "Speed: 2.0ms preprocess, 187.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 183.8ms\n",
      "Speed: 4.0ms preprocess, 183.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 133.3ms\n",
      "Speed: 3.2ms preprocess, 133.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 160.2ms\n",
      "Speed: 2.2ms preprocess, 160.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 133.4ms\n",
      "Speed: 2.0ms preprocess, 133.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 129.0ms\n",
      "Speed: 3.0ms preprocess, 129.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 150.8ms\n",
      "Speed: 2.0ms preprocess, 150.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 181.6ms\n",
      "Speed: 3.0ms preprocess, 181.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 162.3ms\n",
      "Speed: 2.0ms preprocess, 162.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 160.9ms\n",
      "Speed: 2.2ms preprocess, 160.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 153.3ms\n",
      "Speed: 2.4ms preprocess, 153.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 155.0ms\n",
      "Speed: 2.3ms preprocess, 155.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 128.4ms\n",
      "Speed: 4.0ms preprocess, 128.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 142.8ms\n",
      "Speed: 2.2ms preprocess, 142.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 79.1ms\n",
      "Speed: 1.6ms preprocess, 79.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 130.8ms\n",
      "Speed: 3.0ms preprocess, 130.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 91.8ms\n",
      "Speed: 2.5ms preprocess, 91.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 141.7ms\n",
      "Speed: 2.0ms preprocess, 141.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 105.8ms\n",
      "Speed: 2.1ms preprocess, 105.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 141.3ms\n",
      "Speed: 3.3ms preprocess, 141.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 145.3ms\n",
      "Speed: 3.0ms preprocess, 145.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 91.0ms\n",
      "Speed: 1.0ms preprocess, 91.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 107.7ms\n",
      "Speed: 2.0ms preprocess, 107.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 103.4ms\n",
      "Speed: 1.0ms preprocess, 103.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 95.0ms\n",
      "Speed: 2.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 102.4ms\n",
      "Speed: 1.0ms preprocess, 102.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 104.2ms\n",
      "Speed: 3.0ms preprocess, 104.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 106.6ms\n",
      "Speed: 2.1ms preprocess, 106.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 116.0ms\n",
      "Speed: 3.0ms preprocess, 116.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 111.1ms\n",
      "Speed: 2.2ms preprocess, 111.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 98.6ms\n",
      "Speed: 2.0ms preprocess, 98.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 85.7ms\n",
      "Speed: 1.5ms preprocess, 85.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 93.3ms\n",
      "Speed: 2.0ms preprocess, 93.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 86.9ms\n",
      "Speed: 0.9ms preprocess, 86.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 94.9ms\n",
      "Speed: 3.1ms preprocess, 94.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 87.5ms\n",
      "Speed: 1.0ms preprocess, 87.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 86.7ms\n",
      "Speed: 1.0ms preprocess, 86.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 86.6ms\n",
      "Speed: 2.0ms preprocess, 86.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 115.3ms\n",
      "Speed: 2.4ms preprocess, 115.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 85.8ms\n",
      "Speed: 1.1ms preprocess, 85.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 134.9ms\n",
      "Speed: 2.9ms preprocess, 134.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 100.0ms\n",
      "Speed: 2.0ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 96.3ms\n",
      "Speed: 2.0ms preprocess, 96.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 153.8ms\n",
      "Speed: 2.0ms preprocess, 153.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 199.2ms\n",
      "Speed: 4.0ms preprocess, 199.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 166.7ms\n",
      "Speed: 2.0ms preprocess, 166.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 178.3ms\n",
      "Speed: 1.0ms preprocess, 178.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 148.2ms\n",
      "Speed: 3.0ms preprocess, 148.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 152.5ms\n",
      "Speed: 3.0ms preprocess, 152.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 152.2ms\n",
      "Speed: 3.0ms preprocess, 152.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 153.8ms\n",
      "Speed: 2.0ms preprocess, 153.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 139.4ms\n",
      "Speed: 3.0ms preprocess, 139.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 131.2ms\n",
      "Speed: 2.5ms preprocess, 131.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 143.6ms\n",
      "Speed: 2.0ms preprocess, 143.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 134.3ms\n",
      "Speed: 4.0ms preprocess, 134.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 165.3ms\n",
      "Speed: 3.0ms preprocess, 165.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 165.3ms\n",
      "Speed: 2.9ms preprocess, 165.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 170.2ms\n",
      "Speed: 3.0ms preprocess, 170.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 116.3ms\n",
      "Speed: 2.4ms preprocess, 116.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 137.9ms\n",
      "Speed: 3.0ms preprocess, 137.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 155.2ms\n",
      "Speed: 4.6ms preprocess, 155.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 102.1ms\n",
      "Speed: 2.0ms preprocess, 102.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 128.7ms\n",
      "Speed: 2.0ms preprocess, 128.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 109.0ms\n",
      "Speed: 2.3ms preprocess, 109.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 85.8ms\n",
      "Speed: 2.0ms preprocess, 85.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 154.3ms\n",
      "Speed: 2.0ms preprocess, 154.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 147.8ms\n",
      "Speed: 3.0ms preprocess, 147.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 122.8ms\n",
      "Speed: 2.5ms preprocess, 122.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 162.4ms\n",
      "Speed: 3.0ms preprocess, 162.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 180.0ms\n",
      "Speed: 2.7ms preprocess, 180.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 178.9ms\n",
      "Speed: 2.0ms preprocess, 178.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 124.3ms\n",
      "Speed: 3.0ms preprocess, 124.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 100.3ms\n",
      "Speed: 2.0ms preprocess, 100.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 131.5ms\n",
      "Speed: 3.0ms preprocess, 131.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 93.0ms\n",
      "Speed: 2.2ms preprocess, 93.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 125.1ms\n",
      "Speed: 2.0ms preprocess, 125.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 112.1ms\n",
      "Speed: 3.0ms preprocess, 112.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 98.5ms\n",
      "Speed: 1.0ms preprocess, 98.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 154.7ms\n",
      "Speed: 2.1ms preprocess, 154.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 148.7ms\n",
      "Speed: 3.0ms preprocess, 148.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 125.4ms\n",
      "Speed: 3.0ms preprocess, 125.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 165.6ms\n",
      "Speed: 3.4ms preprocess, 165.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 174.8ms\n",
      "Speed: 3.0ms preprocess, 174.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 149.9ms\n",
      "Speed: 3.5ms preprocess, 149.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 163.9ms\n",
      "Speed: 2.0ms preprocess, 163.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 109.0ms\n",
      "Speed: 3.0ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 107.5ms\n",
      "Speed: 1.7ms preprocess, 107.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 114.1ms\n",
      "Speed: 2.9ms preprocess, 114.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 135.0ms\n",
      "Speed: 2.5ms preprocess, 135.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 120.8ms\n",
      "Speed: 2.0ms preprocess, 120.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 172.3ms\n",
      "Speed: 2.1ms preprocess, 172.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 172.4ms\n",
      "Speed: 2.3ms preprocess, 172.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 92.8ms\n",
      "Speed: 1.4ms preprocess, 92.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 145.9ms\n",
      "Speed: 2.0ms preprocess, 145.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 155.8ms\n",
      "Speed: 3.4ms preprocess, 155.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 110.3ms\n",
      "Speed: 3.3ms preprocess, 110.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 98.8ms\n",
      "Speed: 1.0ms preprocess, 98.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 171.2ms\n",
      "Speed: 3.0ms preprocess, 171.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 148.7ms\n",
      "Speed: 3.0ms preprocess, 148.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 109.3ms\n",
      "Speed: 3.7ms preprocess, 109.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 137.6ms\n",
      "Speed: 3.0ms preprocess, 137.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 168.7ms\n",
      "Speed: 2.0ms preprocess, 168.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 145.9ms\n",
      "Speed: 2.0ms preprocess, 145.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 127.2ms\n",
      "Speed: 3.1ms preprocess, 127.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 136.7ms\n",
      "Speed: 3.0ms preprocess, 136.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 94.2ms\n",
      "Speed: 1.6ms preprocess, 94.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 105.9ms\n",
      "Speed: 1.7ms preprocess, 105.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 159.7ms\n",
      "Speed: 2.8ms preprocess, 159.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 188.9ms\n",
      "Speed: 2.8ms preprocess, 188.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 162.4ms\n",
      "Speed: 3.0ms preprocess, 162.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 153.1ms\n",
      "Speed: 4.0ms preprocess, 153.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 178.0ms\n",
      "Speed: 2.5ms preprocess, 178.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 132.7ms\n",
      "Speed: 1.9ms preprocess, 132.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 171.5ms\n",
      "Speed: 2.0ms preprocess, 171.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 131.3ms\n",
      "Speed: 2.0ms preprocess, 131.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 113.7ms\n",
      "Speed: 2.0ms preprocess, 113.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 121.9ms\n",
      "Speed: 1.1ms preprocess, 121.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 103.7ms\n",
      "Speed: 3.9ms preprocess, 103.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 183.0ms\n",
      "Speed: 3.0ms preprocess, 183.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 148.4ms\n",
      "Speed: 2.0ms preprocess, 148.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 142.5ms\n",
      "Speed: 3.0ms preprocess, 142.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 154.9ms\n",
      "Speed: 2.6ms preprocess, 154.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 123.9ms\n",
      "Speed: 1.2ms preprocess, 123.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 96.4ms\n",
      "Speed: 3.0ms preprocess, 96.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 78.1ms\n",
      "Speed: 1.0ms preprocess, 78.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 80.2ms\n",
      "Speed: 1.0ms preprocess, 80.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 76.4ms\n",
      "Speed: 2.0ms preprocess, 76.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 83.3ms\n",
      "Speed: 1.0ms preprocess, 83.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 100.0ms\n",
      "Speed: 1.0ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 188.9ms\n",
      "Speed: 2.0ms preprocess, 188.9ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 159.3ms\n",
      "Speed: 4.0ms preprocess, 159.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 173.2ms\n",
      "Speed: 3.4ms preprocess, 173.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 183.7ms\n",
      "Speed: 3.0ms preprocess, 183.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 173.4ms\n",
      "Speed: 2.0ms preprocess, 173.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 143.9ms\n",
      "Speed: 3.9ms preprocess, 143.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 155.7ms\n",
      "Speed: 3.0ms preprocess, 155.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 158.4ms\n",
      "Speed: 4.0ms preprocess, 158.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 170.1ms\n",
      "Speed: 3.1ms preprocess, 170.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 173.8ms\n",
      "Speed: 2.0ms preprocess, 173.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 170.3ms\n",
      "Speed: 3.0ms preprocess, 170.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 200.4ms\n",
      "Speed: 3.0ms preprocess, 200.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 181.2ms\n",
      "Speed: 2.8ms preprocess, 181.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 155.4ms\n",
      "Speed: 2.2ms preprocess, 155.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 168.4ms\n",
      "Speed: 2.0ms preprocess, 168.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 160.2ms\n",
      "Speed: 2.6ms preprocess, 160.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 186.2ms\n",
      "Speed: 3.0ms preprocess, 186.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 176.1ms\n",
      "Speed: 3.0ms preprocess, 176.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\gorme\\projects\\godseye\\apps\\backend\\Pose-Estimation-Ultralytics\\runs\\pose\\predict16\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the datasett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 102.5ms\n",
      "Speed: 0.0ms preprocess, 102.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.0ms\n",
      "Speed: 0.0ms preprocess, 93.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.8ms\n",
      "Speed: 0.0ms preprocess, 89.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.7ms\n",
      "Speed: 0.0ms preprocess, 94.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 123.1ms\n",
      "Speed: 0.0ms preprocess, 123.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.3ms\n",
      "Speed: 1.0ms preprocess, 99.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.4ms\n",
      "Speed: 0.0ms preprocess, 87.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.4ms\n",
      "Speed: 1.6ms preprocess, 83.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 111.9ms\n",
      "Speed: 0.0ms preprocess, 111.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 101.6ms\n",
      "Speed: 7.7ms preprocess, 101.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 111.0ms\n",
      "Speed: 3.1ms preprocess, 111.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 108.5ms\n",
      "Speed: 0.5ms preprocess, 108.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.4ms\n",
      "Speed: 2.5ms preprocess, 105.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.1ms\n",
      "Speed: 0.0ms preprocess, 83.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.0ms\n",
      "Speed: 3.5ms preprocess, 103.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.6ms\n",
      "Speed: 0.0ms preprocess, 100.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 92.8ms\n",
      "Speed: 7.1ms preprocess, 92.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.5ms\n",
      "Speed: 0.0ms preprocess, 114.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.5ms\n",
      "Speed: 8.5ms preprocess, 113.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.1ms\n",
      "Speed: 0.0ms preprocess, 83.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 90.6ms\n",
      "Speed: 0.0ms preprocess, 90.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 90.9ms\n",
      "Speed: 0.0ms preprocess, 90.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.5ms\n",
      "Speed: 2.5ms preprocess, 76.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.3ms\n",
      "Speed: 0.0ms preprocess, 70.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.8ms\n",
      "Speed: 1.0ms preprocess, 80.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.7ms\n",
      "Speed: 0.0ms preprocess, 86.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.9ms\n",
      "Speed: 0.0ms preprocess, 99.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 215.7ms\n",
      "Speed: 3.6ms preprocess, 215.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 249.4ms\n",
      "Speed: 4.1ms preprocess, 249.4ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 266.0ms\n",
      "Speed: 4.0ms preprocess, 266.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 250.2ms\n",
      "Speed: 0.0ms preprocess, 250.2ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 232.1ms\n",
      "Speed: 2.7ms preprocess, 232.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 250.7ms\n",
      "Speed: 3.4ms preprocess, 250.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 237.0ms\n",
      "Speed: 2.8ms preprocess, 237.0ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 223.8ms\n",
      "Speed: 4.2ms preprocess, 223.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 193.3ms\n",
      "Speed: 0.0ms preprocess, 193.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 247.8ms\n",
      "Speed: 3.0ms preprocess, 247.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 164.4ms\n",
      "Speed: 2.1ms preprocess, 164.4ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 146.4ms\n",
      "Speed: 0.0ms preprocess, 146.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 191.7ms\n",
      "Speed: 2.0ms preprocess, 191.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 196.2ms\n",
      "Speed: 2.0ms preprocess, 196.2ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 241.4ms\n",
      "Speed: 0.0ms preprocess, 241.4ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 298.1ms\n",
      "Speed: 0.3ms preprocess, 298.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 512.1ms\n",
      "Speed: 7.8ms preprocess, 512.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 187.5ms\n",
      "Speed: 2.6ms preprocess, 187.5ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 239.7ms\n",
      "Speed: 0.0ms preprocess, 239.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 250.7ms\n",
      "Speed: 3.3ms preprocess, 250.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 270.5ms\n",
      "Speed: 3.3ms preprocess, 270.5ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 272.8ms\n",
      "Speed: 4.9ms preprocess, 272.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 265.8ms\n",
      "Speed: 4.1ms preprocess, 265.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 261.6ms\n",
      "Speed: 0.0ms preprocess, 261.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 264.3ms\n",
      "Speed: 4.1ms preprocess, 264.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 242.2ms\n",
      "Speed: 5.2ms preprocess, 242.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 262.2ms\n",
      "Speed: 5.2ms preprocess, 262.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 223.2ms\n",
      "Speed: 7.1ms preprocess, 223.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 260.1ms\n",
      "Speed: 3.5ms preprocess, 260.1ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 246.9ms\n",
      "Speed: 4.0ms preprocess, 246.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 248.2ms\n",
      "Speed: 4.4ms preprocess, 248.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 247.1ms\n",
      "Speed: 5.3ms preprocess, 247.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 127.4ms\n",
      "Speed: 6.1ms preprocess, 127.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 192.5ms\n",
      "Speed: 7.3ms preprocess, 192.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 264.4ms\n",
      "Speed: 3.6ms preprocess, 264.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 251.6ms\n",
      "Speed: 3.4ms preprocess, 251.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 259.8ms\n",
      "Speed: 0.0ms preprocess, 259.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 251.0ms\n",
      "Speed: 0.0ms preprocess, 251.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 266.7ms\n",
      "Speed: 0.0ms preprocess, 266.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 265.1ms\n",
      "Speed: 5.1ms preprocess, 265.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 259.3ms\n",
      "Speed: 6.4ms preprocess, 259.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 260.2ms\n",
      "Speed: 2.4ms preprocess, 260.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 260.0ms\n",
      "Speed: 4.6ms preprocess, 260.0ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 269.4ms\n",
      "Speed: 3.5ms preprocess, 269.4ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 266.5ms\n",
      "Speed: 0.0ms preprocess, 266.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 253.5ms\n",
      "Speed: 3.0ms preprocess, 253.5ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 236.6ms\n",
      "Speed: 4.2ms preprocess, 236.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 268.6ms\n",
      "Speed: 0.0ms preprocess, 268.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 250.1ms\n",
      "Speed: 7.6ms preprocess, 250.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 251.6ms\n",
      "Speed: 3.7ms preprocess, 251.6ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 263.1ms\n",
      "Speed: 2.3ms preprocess, 263.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 244.7ms\n",
      "Speed: 2.7ms preprocess, 244.7ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 230.8ms\n",
      "Speed: 8.1ms preprocess, 230.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 210.4ms\n",
      "Speed: 4.1ms preprocess, 210.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 247.0ms\n",
      "Speed: 2.9ms preprocess, 247.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 260.3ms\n",
      "Speed: 3.7ms preprocess, 260.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 275.2ms\n",
      "Speed: 1.4ms preprocess, 275.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 252.9ms\n",
      "Speed: 4.8ms preprocess, 252.9ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 249.9ms\n",
      "Speed: 0.0ms preprocess, 249.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 270.3ms\n",
      "Speed: 2.2ms preprocess, 270.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 252.0ms\n",
      "Speed: 3.5ms preprocess, 252.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 244.0ms\n",
      "Speed: 3.0ms preprocess, 244.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 257.7ms\n",
      "Speed: 5.1ms preprocess, 257.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 246.9ms\n",
      "Speed: 1.0ms preprocess, 246.9ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 271.9ms\n",
      "Speed: 3.0ms preprocess, 271.9ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 213.1ms\n",
      "Speed: 4.1ms preprocess, 213.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 164.5ms\n",
      "Speed: 0.0ms preprocess, 164.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 105.8ms\n",
      "Speed: 4.2ms preprocess, 105.8ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 138.6ms\n",
      "Speed: 2.4ms preprocess, 138.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 226.2ms\n",
      "Speed: 2.0ms preprocess, 226.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 255.6ms\n",
      "Speed: 3.0ms preprocess, 255.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 180.9ms\n",
      "Speed: 2.4ms preprocess, 180.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 151.8ms\n",
      "Speed: 0.0ms preprocess, 151.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 145.9ms\n",
      "Speed: 1.1ms preprocess, 145.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 147.6ms\n",
      "Speed: 1.8ms preprocess, 147.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 121.2ms\n",
      "Speed: 2.2ms preprocess, 121.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 171.8ms\n",
      "Speed: 1.6ms preprocess, 171.8ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 266.6ms\n",
      "Speed: 1.9ms preprocess, 266.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 185.1ms\n",
      "Speed: 1.8ms preprocess, 185.1ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 241.3ms\n",
      "Speed: 2.8ms preprocess, 241.3ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 168.3ms\n",
      "Speed: 2.1ms preprocess, 168.3ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 169.5ms\n",
      "Speed: 1.8ms preprocess, 169.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 219.8ms\n",
      "Speed: 2.6ms preprocess, 219.8ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 240.9ms\n",
      "Speed: 3.0ms preprocess, 240.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 251.4ms\n",
      "Speed: 2.0ms preprocess, 251.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 274.9ms\n",
      "Speed: 2.6ms preprocess, 274.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 330.9ms\n",
      "Speed: 6.5ms preprocess, 330.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 224.8ms\n",
      "Speed: 2.9ms preprocess, 224.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 185.4ms\n",
      "Speed: 5.0ms preprocess, 185.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 512.7ms\n",
      "Speed: 7.9ms preprocess, 512.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 213.0ms\n",
      "Speed: 3.6ms preprocess, 213.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 190.0ms\n",
      "Speed: 3.2ms preprocess, 190.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 188.5ms\n",
      "Speed: 3.5ms preprocess, 188.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 266.0ms\n",
      "Speed: 4.4ms preprocess, 266.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 364.3ms\n",
      "Speed: 5.4ms preprocess, 364.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 209.7ms\n",
      "Speed: 0.0ms preprocess, 209.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 316.5ms\n",
      "Speed: 1.4ms preprocess, 316.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 439.5ms\n",
      "Speed: 7.6ms preprocess, 439.5ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 241.8ms\n",
      "Speed: 6.5ms preprocess, 241.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 215.6ms\n",
      "Speed: 3.6ms preprocess, 215.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 267.8ms\n",
      "Speed: 6.0ms preprocess, 267.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 224.4ms\n",
      "Speed: 3.5ms preprocess, 224.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 280.8ms\n",
      "Speed: 2.9ms preprocess, 280.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 244.8ms\n",
      "Speed: 2.3ms preprocess, 244.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 259.7ms\n",
      "Speed: 2.5ms preprocess, 259.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 254.2ms\n",
      "Speed: 2.0ms preprocess, 254.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 331.0ms\n",
      "Speed: 6.6ms preprocess, 331.0ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 398.5ms\n",
      "Speed: 4.0ms preprocess, 398.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 297.0ms\n",
      "Speed: 10.1ms preprocess, 297.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 324.7ms\n",
      "Speed: 4.0ms preprocess, 324.7ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 281.6ms\n",
      "Speed: 4.6ms preprocess, 281.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 327.9ms\n",
      "Speed: 4.3ms preprocess, 327.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 265.1ms\n",
      "Speed: 5.0ms preprocess, 265.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 244.8ms\n",
      "Speed: 6.4ms preprocess, 244.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 236.1ms\n",
      "Speed: 3.5ms preprocess, 236.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 260.8ms\n",
      "Speed: 3.0ms preprocess, 260.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 257.0ms\n",
      "Speed: 3.0ms preprocess, 257.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 283.4ms\n",
      "Speed: 3.0ms preprocess, 283.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 131.9ms\n",
      "Speed: 2.0ms preprocess, 131.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 125.9ms\n",
      "Speed: 2.0ms preprocess, 125.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 113.2ms\n",
      "Speed: 2.0ms preprocess, 113.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 137.8ms\n",
      "Speed: 2.0ms preprocess, 137.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 146.3ms\n",
      "Speed: 2.0ms preprocess, 146.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 171.2ms\n",
      "Speed: 1.0ms preprocess, 171.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 559.2ms\n",
      "Speed: 3.0ms preprocess, 559.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 368.8ms\n",
      "Speed: 0.0ms preprocess, 368.8ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 333.7ms\n",
      "Speed: 3.9ms preprocess, 333.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 264.9ms\n",
      "Speed: 3.9ms preprocess, 264.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 358.3ms\n",
      "Speed: 3.0ms preprocess, 358.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 712.9ms\n",
      "Speed: 48.8ms preprocess, 712.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 283.2ms\n",
      "Speed: 9.7ms preprocess, 283.2ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 287.2ms\n",
      "Speed: 6.5ms preprocess, 287.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 282.6ms\n",
      "Speed: 10.5ms preprocess, 282.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 283.4ms\n",
      "Speed: 4.5ms preprocess, 283.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.4ms\n",
      "Speed: 0.0ms preprocess, 318.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 299.0ms\n",
      "Speed: 3.7ms preprocess, 299.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 259.6ms\n",
      "Speed: 4.4ms preprocess, 259.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 284.4ms\n",
      "Speed: 5.5ms preprocess, 284.4ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 402.7ms\n",
      "Speed: 5.2ms preprocess, 402.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 307.7ms\n",
      "Speed: 6.7ms preprocess, 307.7ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 284.1ms\n",
      "Speed: 6.1ms preprocess, 284.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 285.4ms\n",
      "Speed: 13.6ms preprocess, 285.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1132.6ms\n",
      "Speed: 2.7ms preprocess, 1132.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 474.3ms\n",
      "Speed: 49.6ms preprocess, 474.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 235.7ms\n",
      "Speed: 1.0ms preprocess, 235.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 160.1ms\n",
      "Speed: 0.0ms preprocess, 160.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 150.1ms\n",
      "Speed: 0.1ms preprocess, 150.1ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 167.5ms\n",
      "Speed: 5.2ms preprocess, 167.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 205.8ms\n",
      "Speed: 1.6ms preprocess, 205.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 257.5ms\n",
      "Speed: 3.0ms preprocess, 257.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 254.2ms\n",
      "Speed: 3.2ms preprocess, 254.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 263.8ms\n",
      "Speed: 4.0ms preprocess, 263.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 223.6ms\n",
      "Speed: 3.5ms preprocess, 223.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 256.9ms\n",
      "Speed: 2.9ms preprocess, 256.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 262.6ms\n",
      "Speed: 3.1ms preprocess, 262.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 292.6ms\n",
      "Speed: 3.7ms preprocess, 292.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 156.4ms\n",
      "Speed: 2.0ms preprocess, 156.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 214.3ms\n",
      "Speed: 0.0ms preprocess, 214.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 252.8ms\n",
      "Speed: 3.0ms preprocess, 252.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 268.6ms\n",
      "Speed: 4.1ms preprocess, 268.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 259.9ms\n",
      "Speed: 2.7ms preprocess, 259.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 252.0ms\n",
      "Speed: 4.0ms preprocess, 252.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 277.8ms\n",
      "Speed: 4.7ms preprocess, 277.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 270.7ms\n",
      "Speed: 3.0ms preprocess, 270.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 258.0ms\n",
      "Speed: 3.5ms preprocess, 258.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 277.8ms\n",
      "Speed: 3.9ms preprocess, 277.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 255.9ms\n",
      "Speed: 4.0ms preprocess, 255.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 204.4ms\n",
      "Speed: 2.3ms preprocess, 204.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 204.3ms\n",
      "Speed: 3.0ms preprocess, 204.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 211.5ms\n",
      "Speed: 3.6ms preprocess, 211.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 226.5ms\n",
      "Speed: 3.7ms preprocess, 226.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 239.7ms\n",
      "Speed: 3.9ms preprocess, 239.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 218.8ms\n",
      "Speed: 3.5ms preprocess, 218.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 195.3ms\n",
      "Speed: 2.5ms preprocess, 195.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 130.1ms\n",
      "Speed: 1.0ms preprocess, 130.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 163.2ms\n",
      "Speed: 2.0ms preprocess, 163.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 217.2ms\n",
      "Speed: 3.8ms preprocess, 217.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 232.9ms\n",
      "Speed: 4.0ms preprocess, 232.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 215.8ms\n",
      "Speed: 3.3ms preprocess, 215.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 222.1ms\n",
      "Speed: 3.5ms preprocess, 222.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 236.7ms\n",
      "Speed: 3.1ms preprocess, 236.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 206.5ms\n",
      "Speed: 3.6ms preprocess, 206.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 225.5ms\n",
      "Speed: 2.6ms preprocess, 225.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 209.1ms\n",
      "Speed: 3.0ms preprocess, 209.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 225.9ms\n",
      "Speed: 3.0ms preprocess, 225.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 224.7ms\n",
      "Speed: 3.6ms preprocess, 224.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 228.1ms\n",
      "Speed: 3.9ms preprocess, 228.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 210.2ms\n",
      "Speed: 4.5ms preprocess, 210.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 183.9ms\n",
      "Speed: 3.0ms preprocess, 183.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 180.4ms\n",
      "Speed: 2.0ms preprocess, 180.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 182.6ms\n",
      "Speed: 3.0ms preprocess, 182.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 175.5ms\n",
      "Speed: 3.7ms preprocess, 175.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 134.0ms\n",
      "Speed: 0.9ms preprocess, 134.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 217.3ms\n",
      "Speed: 2.0ms preprocess, 217.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 207.3ms\n",
      "Speed: 3.4ms preprocess, 207.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 226.1ms\n",
      "Speed: 3.0ms preprocess, 226.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 217.9ms\n",
      "Speed: 3.5ms preprocess, 217.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 230.8ms\n",
      "Speed: 4.0ms preprocess, 230.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 214.6ms\n",
      "Speed: 5.5ms preprocess, 214.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 210.6ms\n",
      "Speed: 3.0ms preprocess, 210.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 198.5ms\n",
      "Speed: 2.8ms preprocess, 198.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 130.0ms\n",
      "Speed: 2.5ms preprocess, 130.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 174.9ms\n",
      "Speed: 1.0ms preprocess, 174.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 193.1ms\n",
      "Speed: 3.6ms preprocess, 193.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 205.5ms\n",
      "Speed: 3.1ms preprocess, 205.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 229.9ms\n",
      "Speed: 2.9ms preprocess, 229.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 226.2ms\n",
      "Speed: 2.4ms preprocess, 226.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 238.1ms\n",
      "Speed: 8.7ms preprocess, 238.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 236.1ms\n",
      "Speed: 4.6ms preprocess, 236.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 259.2ms\n",
      "Speed: 3.7ms preprocess, 259.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 197.2ms\n",
      "Speed: 4.5ms preprocess, 197.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 211.9ms\n",
      "Speed: 3.6ms preprocess, 211.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 234.8ms\n",
      "Speed: 3.5ms preprocess, 234.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 219.8ms\n",
      "Speed: 4.2ms preprocess, 219.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 220.4ms\n",
      "Speed: 3.0ms preprocess, 220.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 229.3ms\n",
      "Speed: 4.3ms preprocess, 229.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 248.7ms\n",
      "Speed: 3.6ms preprocess, 248.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 225.9ms\n",
      "Speed: 3.6ms preprocess, 225.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 233.0ms\n",
      "Speed: 4.2ms preprocess, 233.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 232.1ms\n",
      "Speed: 3.0ms preprocess, 232.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 233.0ms\n",
      "Speed: 3.5ms preprocess, 233.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 244.4ms\n",
      "Speed: 3.0ms preprocess, 244.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 256.7ms\n",
      "Speed: 3.6ms preprocess, 256.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 227.6ms\n",
      "Speed: 4.0ms preprocess, 227.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 253.8ms\n",
      "Speed: 3.6ms preprocess, 253.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 243.4ms\n",
      "Speed: 2.6ms preprocess, 243.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 245.1ms\n",
      "Speed: 3.5ms preprocess, 245.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 232.1ms\n",
      "Speed: 2.6ms preprocess, 232.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 228.8ms\n",
      "Speed: 3.0ms preprocess, 228.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 213.8ms\n",
      "Speed: 2.5ms preprocess, 213.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 220.8ms\n",
      "Speed: 2.8ms preprocess, 220.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 220.1ms\n",
      "Speed: 4.0ms preprocess, 220.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 220.6ms\n",
      "Speed: 4.1ms preprocess, 220.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 249.9ms\n",
      "Speed: 4.0ms preprocess, 249.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 247.5ms\n",
      "Speed: 3.0ms preprocess, 247.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 223.0ms\n",
      "Speed: 3.8ms preprocess, 223.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 233.3ms\n",
      "Speed: 3.4ms preprocess, 233.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 229.4ms\n",
      "Speed: 3.7ms preprocess, 229.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 229.2ms\n",
      "Speed: 2.6ms preprocess, 229.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 217.8ms\n",
      "Speed: 1.9ms preprocess, 217.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 223.6ms\n",
      "Speed: 3.0ms preprocess, 223.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 224.7ms\n",
      "Speed: 2.9ms preprocess, 224.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 218.3ms\n",
      "Speed: 2.0ms preprocess, 218.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 231.2ms\n",
      "Speed: 3.0ms preprocess, 231.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 229.8ms\n",
      "Speed: 4.0ms preprocess, 229.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 192.4ms\n",
      "Speed: 4.0ms preprocess, 192.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 212.0ms\n",
      "Speed: 2.0ms preprocess, 212.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 205.3ms\n",
      "Speed: 3.1ms preprocess, 205.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 231.7ms\n",
      "Speed: 4.0ms preprocess, 231.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 214.7ms\n",
      "Speed: 3.6ms preprocess, 214.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 221.5ms\n",
      "Speed: 4.6ms preprocess, 221.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 208.7ms\n",
      "Speed: 3.0ms preprocess, 208.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 213.1ms\n",
      "Speed: 2.0ms preprocess, 213.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 206.2ms\n",
      "Speed: 3.0ms preprocess, 206.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 231.1ms\n",
      "Speed: 2.7ms preprocess, 231.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 198.5ms\n",
      "Speed: 2.9ms preprocess, 198.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 210.1ms\n",
      "Speed: 3.5ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 246.5ms\n",
      "Speed: 3.0ms preprocess, 246.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 260.2ms\n",
      "Speed: 3.0ms preprocess, 260.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 243.9ms\n",
      "Speed: 3.0ms preprocess, 243.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 253.6ms\n",
      "Speed: 3.0ms preprocess, 253.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 238.6ms\n",
      "Speed: 2.0ms preprocess, 238.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 224.2ms\n",
      "Speed: 3.0ms preprocess, 224.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 193.3ms\n",
      "Speed: 5.6ms preprocess, 193.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 172.1ms\n",
      "Speed: 2.0ms preprocess, 172.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 235.5ms\n",
      "Speed: 2.0ms preprocess, 235.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 240.5ms\n",
      "Speed: 4.5ms preprocess, 240.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 240.4ms\n",
      "Speed: 4.0ms preprocess, 240.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 213.8ms\n",
      "Speed: 2.1ms preprocess, 213.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 229.3ms\n",
      "Speed: 4.1ms preprocess, 229.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 248.6ms\n",
      "Speed: 3.0ms preprocess, 248.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 215.2ms\n",
      "Speed: 8.9ms preprocess, 215.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 273.6ms\n",
      "Speed: 4.6ms preprocess, 273.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 245.8ms\n",
      "Speed: 3.5ms preprocess, 245.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 240.2ms\n",
      "Speed: 3.9ms preprocess, 240.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 245.4ms\n",
      "Speed: 3.6ms preprocess, 245.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 245.9ms\n",
      "Speed: 3.9ms preprocess, 245.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 264.7ms\n",
      "Speed: 4.0ms preprocess, 264.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 258.8ms\n",
      "Speed: 2.7ms preprocess, 258.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 259.0ms\n",
      "Speed: 3.6ms preprocess, 259.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 258.9ms\n",
      "Speed: 3.1ms preprocess, 258.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 244.8ms\n",
      "Speed: 4.6ms preprocess, 244.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 253.9ms\n",
      "Speed: 3.2ms preprocess, 253.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 248.5ms\n",
      "Speed: 3.5ms preprocess, 248.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 259.2ms\n",
      "Speed: 3.3ms preprocess, 259.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 234.2ms\n",
      "Speed: 4.0ms preprocess, 234.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 233.0ms\n",
      "Speed: 3.5ms preprocess, 233.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 228.6ms\n",
      "Speed: 3.6ms preprocess, 228.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 202.9ms\n",
      "Speed: 2.5ms preprocess, 202.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 238.5ms\n",
      "Speed: 2.6ms preprocess, 238.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 221.7ms\n",
      "Speed: 3.0ms preprocess, 221.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 239.3ms\n",
      "Speed: 2.0ms preprocess, 239.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 226.1ms\n",
      "Speed: 2.0ms preprocess, 226.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 242.6ms\n",
      "Speed: 3.7ms preprocess, 242.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 234.5ms\n",
      "Speed: 3.7ms preprocess, 234.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 234.5ms\n",
      "Speed: 3.0ms preprocess, 234.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 232.6ms\n",
      "Speed: 3.0ms preprocess, 232.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 251.0ms\n",
      "Speed: 2.9ms preprocess, 251.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 259.5ms\n",
      "Speed: 4.2ms preprocess, 259.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 219.7ms\n",
      "Speed: 4.0ms preprocess, 219.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 230.4ms\n",
      "Speed: 3.0ms preprocess, 230.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 239.1ms\n",
      "Speed: 3.0ms preprocess, 239.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 257.5ms\n",
      "Speed: 2.6ms preprocess, 257.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 251.3ms\n",
      "Speed: 3.0ms preprocess, 251.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 262.0ms\n",
      "Speed: 2.7ms preprocess, 262.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 247.3ms\n",
      "Speed: 3.2ms preprocess, 247.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 246.9ms\n",
      "Speed: 3.9ms preprocess, 246.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 256.2ms\n",
      "Speed: 4.0ms preprocess, 256.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 234.6ms\n",
      "Speed: 5.6ms preprocess, 234.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 218.5ms\n",
      "Speed: 2.7ms preprocess, 218.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 235.1ms\n",
      "Speed: 3.0ms preprocess, 235.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 233.9ms\n",
      "Speed: 3.5ms preprocess, 233.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 235.5ms\n",
      "Speed: 4.1ms preprocess, 235.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 240.3ms\n",
      "Speed: 3.0ms preprocess, 240.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 233.6ms\n",
      "Speed: 2.9ms preprocess, 233.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 239.9ms\n",
      "Speed: 2.9ms preprocess, 239.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 241.8ms\n",
      "Speed: 2.4ms preprocess, 241.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 221.5ms\n",
      "Speed: 3.0ms preprocess, 221.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 248.3ms\n",
      "Speed: 4.5ms preprocess, 248.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 256.2ms\n",
      "Speed: 4.0ms preprocess, 256.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 247.7ms\n",
      "Speed: 4.0ms preprocess, 247.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 248.1ms\n",
      "Speed: 3.9ms preprocess, 248.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 252.5ms\n",
      "Speed: 3.0ms preprocess, 252.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 229.5ms\n",
      "Speed: 4.0ms preprocess, 229.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 229.4ms\n",
      "Speed: 3.9ms preprocess, 229.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 234.2ms\n",
      "Speed: 3.0ms preprocess, 234.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 223.4ms\n",
      "Speed: 3.0ms preprocess, 223.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 238.6ms\n",
      "Speed: 4.3ms preprocess, 238.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 244.9ms\n",
      "Speed: 4.7ms preprocess, 244.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 242.8ms\n",
      "Speed: 3.9ms preprocess, 242.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 187.8ms\n",
      "Speed: 3.0ms preprocess, 187.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 238.5ms\n",
      "Speed: 2.9ms preprocess, 238.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 233.8ms\n",
      "Speed: 4.0ms preprocess, 233.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 233.1ms\n",
      "Speed: 4.1ms preprocess, 233.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 250.3ms\n",
      "Speed: 3.0ms preprocess, 250.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 195.5ms\n",
      "Speed: 3.2ms preprocess, 195.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 224.4ms\n",
      "Speed: 3.0ms preprocess, 224.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 233.1ms\n",
      "Speed: 2.6ms preprocess, 233.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 237.5ms\n",
      "Speed: 3.5ms preprocess, 237.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 243.9ms\n",
      "Speed: 3.0ms preprocess, 243.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 257.2ms\n",
      "Speed: 2.8ms preprocess, 257.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 230.9ms\n",
      "Speed: 3.5ms preprocess, 230.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 160.6ms\n",
      "Speed: 2.9ms preprocess, 160.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 170.1ms\n",
      "Speed: 2.0ms preprocess, 170.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 153.3ms\n",
      "Speed: 1.9ms preprocess, 153.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 162.2ms\n",
      "Speed: 2.0ms preprocess, 162.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 166.9ms\n",
      "Speed: 2.0ms preprocess, 166.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 162.2ms\n",
      "Speed: 2.0ms preprocess, 162.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 167.6ms\n",
      "Speed: 2.0ms preprocess, 167.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 165.7ms\n",
      "Speed: 2.0ms preprocess, 165.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 198.2ms\n",
      "Speed: 2.0ms preprocess, 198.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 237.7ms\n",
      "Speed: 4.0ms preprocess, 237.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 219.3ms\n",
      "Speed: 3.3ms preprocess, 219.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 205.9ms\n",
      "Speed: 2.0ms preprocess, 205.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 230.1ms\n",
      "Speed: 2.3ms preprocess, 230.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 231.1ms\n",
      "Speed: 3.0ms preprocess, 231.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 244.8ms\n",
      "Speed: 4.3ms preprocess, 244.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 186.9ms\n",
      "Speed: 2.0ms preprocess, 186.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 230.4ms\n",
      "Speed: 4.0ms preprocess, 230.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 233.3ms\n",
      "Speed: 3.0ms preprocess, 233.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 241.8ms\n",
      "Speed: 3.2ms preprocess, 241.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 260.5ms\n",
      "Speed: 3.0ms preprocess, 260.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 266.5ms\n",
      "Speed: 3.6ms preprocess, 266.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 264.7ms\n",
      "Speed: 4.5ms preprocess, 264.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 256.4ms\n",
      "Speed: 4.5ms preprocess, 256.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 204.6ms\n",
      "Speed: 2.9ms preprocess, 204.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 233.1ms\n",
      "Speed: 3.0ms preprocess, 233.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 229.4ms\n",
      "Speed: 3.5ms preprocess, 229.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 255.6ms\n",
      "Speed: 4.2ms preprocess, 255.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 240.7ms\n",
      "Speed: 2.9ms preprocess, 240.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 204.8ms\n",
      "Speed: 3.0ms preprocess, 204.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 192.1ms\n",
      "Speed: 4.0ms preprocess, 192.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 168.9ms\n",
      "Speed: 4.7ms preprocess, 168.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 208.9ms\n",
      "Speed: 3.5ms preprocess, 208.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 231.7ms\n",
      "Speed: 3.0ms preprocess, 231.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 195.6ms\n",
      "Speed: 4.6ms preprocess, 195.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 260.2ms\n",
      "Speed: 2.0ms preprocess, 260.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 262.5ms\n",
      "Speed: 3.7ms preprocess, 262.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 262.0ms\n",
      "Speed: 4.0ms preprocess, 262.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 237.1ms\n",
      "Speed: 3.1ms preprocess, 237.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 237.4ms\n",
      "Speed: 2.6ms preprocess, 237.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 250.4ms\n",
      "Speed: 3.0ms preprocess, 250.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 248.9ms\n",
      "Speed: 4.0ms preprocess, 248.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 261.3ms\n",
      "Speed: 4.0ms preprocess, 261.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 237.0ms\n",
      "Speed: 3.7ms preprocess, 237.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 263.2ms\n",
      "Speed: 2.9ms preprocess, 263.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 246.6ms\n",
      "Speed: 2.8ms preprocess, 246.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 230.4ms\n",
      "Speed: 3.0ms preprocess, 230.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 244.5ms\n",
      "Speed: 3.8ms preprocess, 244.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 209.5ms\n",
      "Speed: 2.8ms preprocess, 209.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 237.0ms\n",
      "Speed: 3.0ms preprocess, 237.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 227.8ms\n",
      "Speed: 2.9ms preprocess, 227.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 231.6ms\n",
      "Speed: 4.0ms preprocess, 231.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 222.5ms\n",
      "Speed: 3.0ms preprocess, 222.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 219.4ms\n",
      "Speed: 3.0ms preprocess, 219.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 193.3ms\n",
      "Speed: 2.9ms preprocess, 193.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 181.3ms\n",
      "Speed: 1.9ms preprocess, 181.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 219.9ms\n",
      "Speed: 3.0ms preprocess, 219.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 198.9ms\n",
      "Speed: 2.6ms preprocess, 198.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 218.0ms\n",
      "Speed: 3.6ms preprocess, 218.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 203.2ms\n",
      "Speed: 3.0ms preprocess, 203.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 231.6ms\n",
      "Speed: 3.0ms preprocess, 231.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 244.8ms\n",
      "Speed: 3.4ms preprocess, 244.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 228.1ms\n",
      "Speed: 3.1ms preprocess, 228.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 235.5ms\n",
      "Speed: 3.0ms preprocess, 235.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 227.9ms\n",
      "Speed: 3.0ms preprocess, 227.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 248.8ms\n",
      "Speed: 4.9ms preprocess, 248.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 196.6ms\n",
      "Speed: 2.0ms preprocess, 196.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 225.7ms\n",
      "Speed: 3.9ms preprocess, 225.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 199.4ms\n",
      "Speed: 12.1ms preprocess, 199.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 197.9ms\n",
      "Speed: 2.6ms preprocess, 197.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 221.9ms\n",
      "Speed: 2.9ms preprocess, 221.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 222.2ms\n",
      "Speed: 3.7ms preprocess, 222.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 224.5ms\n",
      "Speed: 3.5ms preprocess, 224.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 225.8ms\n",
      "Speed: 3.0ms preprocess, 225.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 203.1ms\n",
      "Speed: 3.2ms preprocess, 203.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 143.0ms\n",
      "Speed: 2.2ms preprocess, 143.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 208.1ms\n",
      "Speed: 2.6ms preprocess, 208.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 218.9ms\n",
      "Speed: 3.0ms preprocess, 218.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 229.9ms\n",
      "Speed: 3.0ms preprocess, 229.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 221.5ms\n",
      "Speed: 2.5ms preprocess, 221.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 249.5ms\n",
      "Speed: 2.6ms preprocess, 249.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 245.7ms\n",
      "Speed: 4.0ms preprocess, 245.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 209.7ms\n",
      "Speed: 3.2ms preprocess, 209.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 233.9ms\n",
      "Speed: 12.6ms preprocess, 233.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 240.7ms\n",
      "Speed: 3.7ms preprocess, 240.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 232.9ms\n",
      "Speed: 3.6ms preprocess, 232.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 238.3ms\n",
      "Speed: 4.6ms preprocess, 238.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 202.1ms\n",
      "Speed: 3.6ms preprocess, 202.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 241.0ms\n",
      "Speed: 2.5ms preprocess, 241.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 234.3ms\n",
      "Speed: 3.7ms preprocess, 234.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 248.6ms\n",
      "Speed: 2.9ms preprocess, 248.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 235.1ms\n",
      "Speed: 3.6ms preprocess, 235.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 229.7ms\n",
      "Speed: 4.0ms preprocess, 229.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 260.3ms\n",
      "Speed: 3.0ms preprocess, 260.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 243.3ms\n",
      "Speed: 4.0ms preprocess, 243.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 243.4ms\n",
      "Speed: 3.0ms preprocess, 243.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 244.5ms\n",
      "Speed: 2.7ms preprocess, 244.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 237.3ms\n",
      "Speed: 13.5ms preprocess, 237.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 250.2ms\n",
      "Speed: 2.7ms preprocess, 250.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 232.4ms\n",
      "Speed: 4.0ms preprocess, 232.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 267.6ms\n",
      "Speed: 4.0ms preprocess, 267.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 240.8ms\n",
      "Speed: 2.9ms preprocess, 240.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 239.4ms\n",
      "Speed: 5.0ms preprocess, 239.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 251.9ms\n",
      "Speed: 4.0ms preprocess, 251.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 229.9ms\n",
      "Speed: 4.0ms preprocess, 229.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 214.6ms\n",
      "Speed: 3.5ms preprocess, 214.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 233.6ms\n",
      "Speed: 3.0ms preprocess, 233.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 222.8ms\n",
      "Speed: 2.0ms preprocess, 222.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 255.4ms\n",
      "Speed: 3.0ms preprocess, 255.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 217.0ms\n",
      "Speed: 4.0ms preprocess, 217.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 262.5ms\n",
      "Speed: 3.1ms preprocess, 262.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 241.2ms\n",
      "Speed: 13.0ms preprocess, 241.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 231.9ms\n",
      "Speed: 3.9ms preprocess, 231.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 213.1ms\n",
      "Speed: 4.1ms preprocess, 213.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 240.9ms\n",
      "Speed: 3.5ms preprocess, 240.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 252.4ms\n",
      "Speed: 3.0ms preprocess, 252.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 247.1ms\n",
      "Speed: 3.0ms preprocess, 247.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 213.8ms\n",
      "Speed: 4.0ms preprocess, 213.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 234.6ms\n",
      "Speed: 2.1ms preprocess, 234.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 250.8ms\n",
      "Speed: 3.7ms preprocess, 250.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 254.0ms\n",
      "Speed: 3.3ms preprocess, 254.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 199.5ms\n",
      "Speed: 3.1ms preprocess, 199.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 266.9ms\n",
      "Speed: 3.9ms preprocess, 266.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 275.4ms\n",
      "Speed: 3.6ms preprocess, 275.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 278.6ms\n",
      "Speed: 4.0ms preprocess, 278.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 266.6ms\n",
      "Speed: 5.0ms preprocess, 266.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 267.8ms\n",
      "Speed: 4.5ms preprocess, 267.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 249.1ms\n",
      "Speed: 2.9ms preprocess, 249.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 242.5ms\n",
      "Speed: 3.0ms preprocess, 242.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 238.7ms\n",
      "Speed: 4.0ms preprocess, 238.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 242.4ms\n",
      "Speed: 3.6ms preprocess, 242.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 236.0ms\n",
      "Speed: 4.0ms preprocess, 236.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 188.4ms\n",
      "Speed: 2.0ms preprocess, 188.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 244.0ms\n",
      "Speed: 3.0ms preprocess, 244.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 256.9ms\n",
      "Speed: 2.9ms preprocess, 256.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 242.0ms\n",
      "Speed: 3.5ms preprocess, 242.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 249.5ms\n",
      "Speed: 4.0ms preprocess, 249.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 222.9ms\n",
      "Speed: 2.9ms preprocess, 222.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 213.4ms\n",
      "Speed: 4.0ms preprocess, 213.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 221.2ms\n",
      "Speed: 3.9ms preprocess, 221.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 250.0ms\n",
      "Speed: 3.5ms preprocess, 250.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 247.3ms\n",
      "Speed: 2.6ms preprocess, 247.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 265.1ms\n",
      "Speed: 4.6ms preprocess, 265.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 248.4ms\n",
      "Speed: 3.1ms preprocess, 248.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 241.7ms\n",
      "Speed: 4.6ms preprocess, 241.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 249.2ms\n",
      "Speed: 4.6ms preprocess, 249.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 215.5ms\n",
      "Speed: 3.0ms preprocess, 215.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 220.7ms\n",
      "Speed: 2.9ms preprocess, 220.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 252.4ms\n",
      "Speed: 3.0ms preprocess, 252.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 264.2ms\n",
      "Speed: 4.5ms preprocess, 264.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 278.6ms\n",
      "Speed: 4.0ms preprocess, 278.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 275.2ms\n",
      "Speed: 4.0ms preprocess, 275.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 253.2ms\n",
      "Speed: 4.4ms preprocess, 253.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 231.4ms\n",
      "Speed: 3.0ms preprocess, 231.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 241.3ms\n",
      "Speed: 2.9ms preprocess, 241.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 229.6ms\n",
      "Speed: 3.0ms preprocess, 229.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 252.6ms\n",
      "Speed: 3.0ms preprocess, 252.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 223.2ms\n",
      "Speed: 1.7ms preprocess, 223.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 244.4ms\n",
      "Speed: 3.0ms preprocess, 244.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 238.4ms\n",
      "Speed: 3.4ms preprocess, 238.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 264.9ms\n",
      "Speed: 3.7ms preprocess, 264.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 281.1ms\n",
      "Speed: 3.0ms preprocess, 281.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 245.7ms\n",
      "Speed: 3.0ms preprocess, 245.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 223.3ms\n",
      "Speed: 3.0ms preprocess, 223.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 237.1ms\n",
      "Speed: 2.9ms preprocess, 237.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 274.9ms\n",
      "Speed: 2.8ms preprocess, 274.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 236.7ms\n",
      "Speed: 3.0ms preprocess, 236.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 263.6ms\n",
      "Speed: 3.0ms preprocess, 263.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 258.9ms\n",
      "Speed: 3.0ms preprocess, 258.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 280.4ms\n",
      "Speed: 4.9ms preprocess, 280.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 254.2ms\n",
      "Speed: 4.1ms preprocess, 254.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 230.6ms\n",
      "Speed: 2.1ms preprocess, 230.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 187.6ms\n",
      "Speed: 5.0ms preprocess, 187.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 123.2ms\n",
      "Speed: 1.0ms preprocess, 123.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 178.7ms\n",
      "Speed: 2.9ms preprocess, 178.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 194.2ms\n",
      "Speed: 2.4ms preprocess, 194.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 227.4ms\n",
      "Speed: 2.0ms preprocess, 227.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 208.2ms\n",
      "Speed: 3.6ms preprocess, 208.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 232.6ms\n",
      "Speed: 3.0ms preprocess, 232.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 253.1ms\n",
      "Speed: 2.6ms preprocess, 253.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 258.1ms\n",
      "Speed: 4.0ms preprocess, 258.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 134.1ms\n",
      "Speed: 1.0ms preprocess, 134.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 202.6ms\n",
      "Speed: 2.5ms preprocess, 202.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 236.4ms\n",
      "Speed: 4.5ms preprocess, 236.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 230.9ms\n",
      "Speed: 2.6ms preprocess, 230.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 228.0ms\n",
      "Speed: 2.0ms preprocess, 228.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 161.2ms\n",
      "Speed: 2.0ms preprocess, 161.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 239.0ms\n",
      "Speed: 3.0ms preprocess, 239.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 165.3ms\n",
      "Speed: 2.0ms preprocess, 165.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 197.9ms\n",
      "Speed: 2.5ms preprocess, 197.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 235.0ms\n",
      "Speed: 3.0ms preprocess, 235.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 215.0ms\n",
      "Speed: 3.4ms preprocess, 215.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 118.1ms\n",
      "Speed: 2.0ms preprocess, 118.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 169.9ms\n",
      "Speed: 2.0ms preprocess, 169.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 258.5ms\n",
      "Speed: 3.5ms preprocess, 258.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 274.5ms\n",
      "Speed: 4.6ms preprocess, 274.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 261.4ms\n",
      "Speed: 3.6ms preprocess, 261.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 262.0ms\n",
      "Speed: 2.5ms preprocess, 262.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 241.1ms\n",
      "Speed: 3.0ms preprocess, 241.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 240.8ms\n",
      "Speed: 4.0ms preprocess, 240.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 152.1ms\n",
      "Speed: 3.2ms preprocess, 152.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 209.6ms\n",
      "Speed: 4.1ms preprocess, 209.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 213.0ms\n",
      "Speed: 2.5ms preprocess, 213.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 256.9ms\n",
      "Speed: 3.0ms preprocess, 256.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 271.0ms\n",
      "Speed: 2.7ms preprocess, 271.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 234.3ms\n",
      "Speed: 3.7ms preprocess, 234.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 234.2ms\n",
      "Speed: 3.5ms preprocess, 234.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 220.6ms\n",
      "Speed: 2.5ms preprocess, 220.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 225.2ms\n",
      "Speed: 2.0ms preprocess, 225.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 225.9ms\n",
      "Speed: 3.1ms preprocess, 225.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 263.0ms\n",
      "Speed: 3.0ms preprocess, 263.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 177.6ms\n",
      "Speed: 3.6ms preprocess, 177.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 248.0ms\n",
      "Speed: 2.6ms preprocess, 248.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 231.6ms\n",
      "Speed: 2.2ms preprocess, 231.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 268.4ms\n",
      "Speed: 3.0ms preprocess, 268.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 251.6ms\n",
      "Speed: 2.9ms preprocess, 251.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 245.6ms\n",
      "Speed: 3.0ms preprocess, 245.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 233.4ms\n",
      "Speed: 2.8ms preprocess, 233.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 207.4ms\n",
      "Speed: 2.0ms preprocess, 207.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 230.9ms\n",
      "Speed: 3.0ms preprocess, 230.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 210.2ms\n",
      "Speed: 2.0ms preprocess, 210.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 259.5ms\n",
      "Speed: 2.1ms preprocess, 259.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 176.3ms\n",
      "Speed: 2.6ms preprocess, 176.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 191.8ms\n",
      "Speed: 2.0ms preprocess, 191.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 210.6ms\n",
      "Speed: 3.2ms preprocess, 210.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 218.0ms\n",
      "Speed: 4.5ms preprocess, 218.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 174.2ms\n",
      "Speed: 3.0ms preprocess, 174.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 223.4ms\n",
      "Speed: 2.0ms preprocess, 223.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 378.9ms\n",
      "Speed: 3.6ms preprocess, 378.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 337.1ms\n",
      "Speed: 1.2ms preprocess, 337.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 242.9ms\n",
      "Speed: 2.0ms preprocess, 242.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 162.7ms\n",
      "Speed: 3.0ms preprocess, 162.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 349.2ms\n",
      "Speed: 2.3ms preprocess, 349.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 291.5ms\n",
      "Speed: 2.5ms preprocess, 291.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 243.6ms\n",
      "Speed: 2.5ms preprocess, 243.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 319.3ms\n",
      "Speed: 3.3ms preprocess, 319.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 258.5ms\n",
      "Speed: 4.0ms preprocess, 258.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 179.0ms\n",
      "Speed: 2.0ms preprocess, 179.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 149.9ms\n",
      "Speed: 3.0ms preprocess, 149.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 134.7ms\n",
      "Speed: 2.5ms preprocess, 134.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 184.3ms\n",
      "Speed: 2.0ms preprocess, 184.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 207.5ms\n",
      "Speed: 4.1ms preprocess, 207.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 253.0ms\n",
      "Speed: 2.6ms preprocess, 253.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 253.5ms\n",
      "Speed: 3.0ms preprocess, 253.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 229.9ms\n",
      "Speed: 2.0ms preprocess, 229.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 342.0ms\n",
      "Speed: 3.9ms preprocess, 342.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 252.4ms\n",
      "Speed: 9.6ms preprocess, 252.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 376.9ms\n",
      "Speed: 6.0ms preprocess, 376.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 330.4ms\n",
      "Speed: 7.3ms preprocess, 330.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 335.6ms\n",
      "Speed: 4.0ms preprocess, 335.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 301.2ms\n",
      "Speed: 5.6ms preprocess, 301.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 270.6ms\n",
      "Speed: 4.1ms preprocess, 270.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 252.5ms\n",
      "Speed: 2.6ms preprocess, 252.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 207.4ms\n",
      "Speed: 4.0ms preprocess, 207.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 256.6ms\n",
      "Speed: 2.2ms preprocess, 256.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 255.2ms\n",
      "Speed: 3.0ms preprocess, 255.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 247.5ms\n",
      "Speed: 3.0ms preprocess, 247.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 202.9ms\n",
      "Speed: 3.0ms preprocess, 202.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 239.9ms\n",
      "Speed: 4.6ms preprocess, 239.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 268.5ms\n",
      "Speed: 3.5ms preprocess, 268.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 270.5ms\n",
      "Speed: 3.6ms preprocess, 270.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 269.4ms\n",
      "Speed: 4.1ms preprocess, 269.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 275.2ms\n",
      "Speed: 3.0ms preprocess, 275.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 264.2ms\n",
      "Speed: 3.5ms preprocess, 264.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 257.5ms\n",
      "Speed: 2.8ms preprocess, 257.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 274.7ms\n",
      "Speed: 2.9ms preprocess, 274.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 239.5ms\n",
      "Speed: 2.4ms preprocess, 239.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 249.5ms\n",
      "Speed: 4.1ms preprocess, 249.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 263.9ms\n",
      "Speed: 3.0ms preprocess, 263.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 264.1ms\n",
      "Speed: 3.9ms preprocess, 264.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 247.8ms\n",
      "Speed: 2.0ms preprocess, 247.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 264.4ms\n",
      "Speed: 3.7ms preprocess, 264.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 267.7ms\n",
      "Speed: 3.5ms preprocess, 267.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 291.8ms\n",
      "Speed: 4.5ms preprocess, 291.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 249.4ms\n",
      "Speed: 1.7ms preprocess, 249.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 235.0ms\n",
      "Speed: 2.0ms preprocess, 235.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 252.3ms\n",
      "Speed: 3.5ms preprocess, 252.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 236.7ms\n",
      "Speed: 3.0ms preprocess, 236.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 250.2ms\n",
      "Speed: 4.5ms preprocess, 250.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 260.4ms\n",
      "Speed: 3.0ms preprocess, 260.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 238.6ms\n",
      "Speed: 2.1ms preprocess, 238.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 203.3ms\n",
      "Speed: 4.0ms preprocess, 203.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 238.5ms\n",
      "Speed: 2.3ms preprocess, 238.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 259.7ms\n",
      "Speed: 3.1ms preprocess, 259.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 204.5ms\n",
      "Speed: 2.9ms preprocess, 204.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 254.2ms\n",
      "Speed: 2.5ms preprocess, 254.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 270.3ms\n",
      "Speed: 4.6ms preprocess, 270.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 241.8ms\n",
      "Speed: 2.6ms preprocess, 241.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 225.6ms\n",
      "Speed: 4.3ms preprocess, 225.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 124.7ms\n",
      "Speed: 2.0ms preprocess, 124.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 223.1ms\n",
      "Speed: 1.9ms preprocess, 223.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 126.1ms\n",
      "Speed: 1.0ms preprocess, 126.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 205.7ms\n",
      "Speed: 2.0ms preprocess, 205.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 239.5ms\n",
      "Speed: 2.0ms preprocess, 239.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 269.1ms\n",
      "Speed: 4.0ms preprocess, 269.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 158.5ms\n",
      "Speed: 3.4ms preprocess, 158.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 112.9ms\n",
      "Speed: 1.5ms preprocess, 112.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 222.2ms\n",
      "Speed: 2.0ms preprocess, 222.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 300.8ms\n",
      "Speed: 4.4ms preprocess, 300.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 281.1ms\n",
      "Speed: 4.6ms preprocess, 281.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 285.5ms\n",
      "Speed: 4.5ms preprocess, 285.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 296.2ms\n",
      "Speed: 4.0ms preprocess, 296.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 331.8ms\n",
      "Speed: 5.0ms preprocess, 331.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 294.4ms\n",
      "Speed: 4.6ms preprocess, 294.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 264.6ms\n",
      "Speed: 2.6ms preprocess, 264.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 273.2ms\n",
      "Speed: 3.6ms preprocess, 273.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 267.2ms\n",
      "Speed: 3.0ms preprocess, 267.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 266.8ms\n",
      "Speed: 3.1ms preprocess, 266.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 270.2ms\n",
      "Speed: 3.9ms preprocess, 270.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 323.3ms\n",
      "Speed: 2.3ms preprocess, 323.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 154.1ms\n",
      "Speed: 2.6ms preprocess, 154.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 252.0ms\n",
      "Speed: 3.7ms preprocess, 252.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 270.4ms\n",
      "Speed: 1.9ms preprocess, 270.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 243.2ms\n",
      "Speed: 2.4ms preprocess, 243.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 244.8ms\n",
      "Speed: 2.1ms preprocess, 244.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 246.8ms\n",
      "Speed: 2.0ms preprocess, 246.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 268.4ms\n",
      "Speed: 4.0ms preprocess, 268.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 254.6ms\n",
      "Speed: 3.0ms preprocess, 254.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 272.8ms\n",
      "Speed: 5.2ms preprocess, 272.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 265.7ms\n",
      "Speed: 3.8ms preprocess, 265.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 253.9ms\n",
      "Speed: 3.6ms preprocess, 253.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 268.4ms\n",
      "Speed: 3.9ms preprocess, 268.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 275.5ms\n",
      "Speed: 2.9ms preprocess, 275.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 263.8ms\n",
      "Speed: 3.1ms preprocess, 263.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 322.3ms\n",
      "Speed: 5.5ms preprocess, 322.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 215.4ms\n",
      "Speed: 2.0ms preprocess, 215.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 242.6ms\n",
      "Speed: 3.8ms preprocess, 242.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 237.6ms\n",
      "Speed: 4.2ms preprocess, 237.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 253.0ms\n",
      "Speed: 2.0ms preprocess, 253.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 222.5ms\n",
      "Speed: 3.8ms preprocess, 222.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 227.6ms\n",
      "Speed: 2.1ms preprocess, 227.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 178.9ms\n",
      "Speed: 4.6ms preprocess, 178.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 151.9ms\n",
      "Speed: 1.4ms preprocess, 151.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 214.0ms\n",
      "Speed: 1.9ms preprocess, 214.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 260.4ms\n",
      "Speed: 3.0ms preprocess, 260.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 233.5ms\n",
      "Speed: 4.6ms preprocess, 233.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 273.4ms\n",
      "Speed: 3.0ms preprocess, 273.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 250.9ms\n",
      "Speed: 3.0ms preprocess, 250.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 233.2ms\n",
      "Speed: 1.6ms preprocess, 233.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 258.0ms\n",
      "Speed: 3.0ms preprocess, 258.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 283.0ms\n",
      "Speed: 4.2ms preprocess, 283.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 260.7ms\n",
      "Speed: 3.6ms preprocess, 260.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 250.4ms\n",
      "Speed: 3.1ms preprocess, 250.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 246.1ms\n",
      "Speed: 2.9ms preprocess, 246.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 238.0ms\n",
      "Speed: 2.9ms preprocess, 238.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 272.4ms\n",
      "Speed: 4.2ms preprocess, 272.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 250.9ms\n",
      "Speed: 3.6ms preprocess, 250.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 260.3ms\n",
      "Speed: 3.5ms preprocess, 260.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 266.8ms\n",
      "Speed: 3.1ms preprocess, 266.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 245.0ms\n",
      "Speed: 3.6ms preprocess, 245.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 252.3ms\n",
      "Speed: 3.7ms preprocess, 252.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 240.0ms\n",
      "Speed: 2.0ms preprocess, 240.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 259.5ms\n",
      "Speed: 4.7ms preprocess, 259.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 206.7ms\n",
      "Speed: 3.0ms preprocess, 206.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 260.1ms\n",
      "Speed: 3.0ms preprocess, 260.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 232.1ms\n",
      "Speed: 1.9ms preprocess, 232.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 262.3ms\n",
      "Speed: 2.6ms preprocess, 262.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 258.4ms\n",
      "Speed: 2.7ms preprocess, 258.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 256.3ms\n",
      "Speed: 2.7ms preprocess, 256.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 258.9ms\n",
      "Speed: 2.9ms preprocess, 258.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 258.7ms\n",
      "Speed: 1.5ms preprocess, 258.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 185.0ms\n",
      "Speed: 3.3ms preprocess, 185.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 220.6ms\n",
      "Speed: 2.3ms preprocess, 220.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 235.1ms\n",
      "Speed: 3.8ms preprocess, 235.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 217.3ms\n",
      "Speed: 3.0ms preprocess, 217.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 237.9ms\n",
      "Speed: 3.0ms preprocess, 237.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 268.6ms\n",
      "Speed: 3.5ms preprocess, 268.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 271.7ms\n",
      "Speed: 3.6ms preprocess, 271.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 252.5ms\n",
      "Speed: 2.0ms preprocess, 252.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 252.7ms\n",
      "Speed: 2.4ms preprocess, 252.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 214.1ms\n",
      "Speed: 2.0ms preprocess, 214.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 203.8ms\n",
      "Speed: 2.2ms preprocess, 203.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 255.0ms\n",
      "Speed: 2.5ms preprocess, 255.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 265.4ms\n",
      "Speed: 4.3ms preprocess, 265.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 245.2ms\n",
      "Speed: 2.0ms preprocess, 245.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 223.3ms\n",
      "Speed: 3.2ms preprocess, 223.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 243.1ms\n",
      "Speed: 3.0ms preprocess, 243.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 261.7ms\n",
      "Speed: 3.0ms preprocess, 261.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 251.0ms\n",
      "Speed: 3.7ms preprocess, 251.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 234.7ms\n",
      "Speed: 2.1ms preprocess, 234.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 246.7ms\n",
      "Speed: 3.5ms preprocess, 246.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 (no detections), 288.1ms\n",
      "Speed: 4.4ms preprocess, 288.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 284.4ms\n",
      "Speed: 4.9ms preprocess, 284.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 253.2ms\n",
      "Speed: 4.9ms preprocess, 253.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 279.2ms\n",
      "Speed: 7.5ms preprocess, 279.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 250.3ms\n",
      "Speed: 5.7ms preprocess, 250.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 261.1ms\n",
      "Speed: 4.4ms preprocess, 261.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 240.6ms\n",
      "Speed: 4.7ms preprocess, 240.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 236.7ms\n",
      "Speed: 3.6ms preprocess, 236.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 282.3ms\n",
      "Speed: 3.7ms preprocess, 282.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 169.7ms\n",
      "Speed: 4.6ms preprocess, 169.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 160.5ms\n",
      "Speed: 3.6ms preprocess, 160.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 198.1ms\n",
      "Speed: 2.9ms preprocess, 198.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 222.4ms\n",
      "Speed: 4.5ms preprocess, 222.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 214.6ms\n",
      "Speed: 4.1ms preprocess, 214.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 241.9ms\n",
      "Speed: 5.0ms preprocess, 241.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 240.2ms\n",
      "Speed: 4.7ms preprocess, 240.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 215.4ms\n",
      "Speed: 4.5ms preprocess, 215.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 109.3ms\n",
      "Speed: 1.0ms preprocess, 109.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 96.8ms\n",
      "Speed: 3.0ms preprocess, 96.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 92.4ms\n",
      "Speed: 2.0ms preprocess, 92.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 90.0ms\n",
      "Speed: 2.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 91.3ms\n",
      "Speed: 1.6ms preprocess, 91.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 108.4ms\n",
      "Speed: 2.0ms preprocess, 108.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 99.9ms\n",
      "Speed: 2.0ms preprocess, 99.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 108.9ms\n",
      "Speed: 2.2ms preprocess, 108.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 137.0ms\n",
      "Speed: 3.0ms preprocess, 137.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 103.5ms\n",
      "Speed: 2.0ms preprocess, 103.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 114.8ms\n",
      "Speed: 2.1ms preprocess, 114.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 115.8ms\n",
      "Speed: 2.0ms preprocess, 115.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 114.6ms\n",
      "Speed: 3.2ms preprocess, 114.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 91.4ms\n",
      "Speed: 3.0ms preprocess, 91.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 137.9ms\n",
      "Speed: 2.0ms preprocess, 137.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 101.9ms\n",
      "Speed: 3.0ms preprocess, 101.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 104.1ms\n",
      "Speed: 2.0ms preprocess, 104.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 291.6ms\n",
      "Speed: 6.0ms preprocess, 291.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 296.6ms\n",
      "Speed: 6.5ms preprocess, 296.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 338.0ms\n",
      "Speed: 8.0ms preprocess, 338.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 274.3ms\n",
      "Speed: 6.6ms preprocess, 274.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 286.6ms\n",
      "Speed: 5.6ms preprocess, 286.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 258.8ms\n",
      "Speed: 5.8ms preprocess, 258.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 283.9ms\n",
      "Speed: 5.7ms preprocess, 283.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 300.2ms\n",
      "Speed: 6.0ms preprocess, 300.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 291.6ms\n",
      "Speed: 4.4ms preprocess, 291.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 428.3ms\n",
      "Speed: 6.5ms preprocess, 428.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 437.4ms\n",
      "Speed: 4.7ms preprocess, 437.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 420.4ms\n",
      "Speed: 3.1ms preprocess, 420.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 387.2ms\n",
      "Speed: 55.0ms preprocess, 387.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 402.2ms\n",
      "Speed: 5.6ms preprocess, 402.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 257.7ms\n",
      "Speed: 9.8ms preprocess, 257.7ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 405.3ms\n",
      "Speed: 4.4ms preprocess, 405.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 297.3ms\n",
      "Speed: 3.0ms preprocess, 297.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 112.7ms\n",
      "Speed: 3.1ms preprocess, 112.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 130.9ms\n",
      "Speed: 1.5ms preprocess, 130.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 104.6ms\n",
      "Speed: 2.5ms preprocess, 104.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 275.3ms\n",
      "Speed: 1.5ms preprocess, 275.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 412.7ms\n",
      "Speed: 1.6ms preprocess, 412.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 237.5ms\n",
      "Speed: 3.8ms preprocess, 237.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 114.1ms\n",
      "Speed: 4.5ms preprocess, 114.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 117.4ms\n",
      "Speed: 1.5ms preprocess, 117.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 183.7ms\n",
      "Speed: 2.4ms preprocess, 183.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 180.8ms\n",
      "Speed: 1.0ms preprocess, 180.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 171.8ms\n",
      "Speed: 2.0ms preprocess, 171.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 185.2ms\n",
      "Speed: 1.0ms preprocess, 185.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 170.3ms\n",
      "Speed: 6.3ms preprocess, 170.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 97.3ms\n",
      "Speed: 3.0ms preprocess, 97.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 83.3ms\n",
      "Speed: 2.1ms preprocess, 83.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 160.1ms\n",
      "Speed: 2.2ms preprocess, 160.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 122.0ms\n",
      "Speed: 2.0ms preprocess, 122.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 108.4ms\n",
      "Speed: 2.0ms preprocess, 108.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 166.8ms\n",
      "Speed: 2.5ms preprocess, 166.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 629.4ms\n",
      "Speed: 10.2ms preprocess, 629.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 481.0ms\n",
      "Speed: 3.0ms preprocess, 481.0ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 296.8ms\n",
      "Speed: 13.6ms preprocess, 296.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 284.0ms\n",
      "Speed: 5.5ms preprocess, 284.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 288.8ms\n",
      "Speed: 6.3ms preprocess, 288.8ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 281.1ms\n",
      "Speed: 7.0ms preprocess, 281.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 316.0ms\n",
      "Speed: 5.4ms preprocess, 316.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 511.4ms\n",
      "Speed: 16.5ms preprocess, 511.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 521.0ms\n",
      "Speed: 8.4ms preprocess, 521.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 323.7ms\n",
      "Speed: 35.3ms preprocess, 323.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 379.6ms\n",
      "Speed: 6.0ms preprocess, 379.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 229.4ms\n",
      "Speed: 3.1ms preprocess, 229.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 226.0ms\n",
      "Speed: 5.7ms preprocess, 226.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 273.7ms\n",
      "Speed: 4.7ms preprocess, 273.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 290.7ms\n",
      "Speed: 5.5ms preprocess, 290.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 261.3ms\n",
      "Speed: 4.6ms preprocess, 261.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 249.5ms\n",
      "Speed: 4.6ms preprocess, 249.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 268.0ms\n",
      "Speed: 4.2ms preprocess, 268.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 257.0ms\n",
      "Speed: 5.6ms preprocess, 257.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 265.7ms\n",
      "Speed: 5.4ms preprocess, 265.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 270.2ms\n",
      "Speed: 4.2ms preprocess, 270.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 310.3ms\n",
      "Speed: 4.7ms preprocess, 310.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 407.1ms\n",
      "Speed: 4.5ms preprocess, 407.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 345.9ms\n",
      "Speed: 3.0ms preprocess, 345.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 443.1ms\n",
      "Speed: 53.6ms preprocess, 443.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 417.9ms\n",
      "Speed: 9.3ms preprocess, 417.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 260.8ms\n",
      "Speed: 7.4ms preprocess, 260.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 177.9ms\n",
      "Speed: 3.3ms preprocess, 177.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 250.7ms\n",
      "Speed: 3.2ms preprocess, 250.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 189.4ms\n",
      "Speed: 3.3ms preprocess, 189.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 144.4ms\n",
      "Speed: 2.6ms preprocess, 144.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 155.0ms\n",
      "Speed: 2.1ms preprocess, 155.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 194.1ms\n",
      "Speed: 4.0ms preprocess, 194.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 237.7ms\n",
      "Speed: 4.1ms preprocess, 237.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 212.2ms\n",
      "Speed: 4.6ms preprocess, 212.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 102.2ms\n",
      "Speed: 2.2ms preprocess, 102.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 90.1ms\n",
      "Speed: 3.4ms preprocess, 90.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 82.8ms\n",
      "Speed: 2.1ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 86.8ms\n",
      "Speed: 2.6ms preprocess, 86.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 90.4ms\n",
      "Speed: 2.5ms preprocess, 90.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 184.6ms\n",
      "Speed: 3.5ms preprocess, 184.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 199.4ms\n",
      "Speed: 4.6ms preprocess, 199.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 188.4ms\n",
      "Speed: 4.0ms preprocess, 188.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 279.0ms\n",
      "Speed: 5.5ms preprocess, 279.0ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 338.7ms\n",
      "Speed: 10.5ms preprocess, 338.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 522.7ms\n",
      "Speed: 70.3ms preprocess, 522.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 330.5ms\n",
      "Speed: 4.7ms preprocess, 330.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 279.3ms\n",
      "Speed: 4.3ms preprocess, 279.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 995.6ms\n",
      "Speed: 5.4ms preprocess, 995.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1306.0ms\n",
      "Speed: 4.7ms preprocess, 1306.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 143.4ms\n",
      "Speed: 3.6ms preprocess, 143.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 179.0ms\n",
      "Speed: 3.5ms preprocess, 179.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 181.1ms\n",
      "Speed: 3.9ms preprocess, 181.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 127.8ms\n",
      "Speed: 2.2ms preprocess, 127.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 147.5ms\n",
      "Speed: 3.0ms preprocess, 147.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 186.3ms\n",
      "Speed: 3.0ms preprocess, 186.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 255.4ms\n",
      "Speed: 5.0ms preprocess, 255.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 230.3ms\n",
      "Speed: 4.0ms preprocess, 230.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 200.8ms\n",
      "Speed: 3.7ms preprocess, 200.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 300.0ms\n",
      "Speed: 3.0ms preprocess, 300.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 272.7ms\n",
      "Speed: 6.6ms preprocess, 272.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 417.1ms\n",
      "Speed: 3.1ms preprocess, 417.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 269.8ms\n",
      "Speed: 4.1ms preprocess, 269.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 192.5ms\n",
      "Speed: 4.4ms preprocess, 192.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 173.8ms\n",
      "Speed: 3.6ms preprocess, 173.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 230.2ms\n",
      "Speed: 5.6ms preprocess, 230.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 243.5ms\n",
      "Speed: 3.7ms preprocess, 243.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 246.7ms\n",
      "Speed: 4.7ms preprocess, 246.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 231.9ms\n",
      "Speed: 3.7ms preprocess, 231.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 183.6ms\n",
      "Speed: 4.1ms preprocess, 183.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 240.3ms\n",
      "Speed: 3.6ms preprocess, 240.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 270.8ms\n",
      "Speed: 4.0ms preprocess, 270.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 272.1ms\n",
      "Speed: 4.6ms preprocess, 272.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 253.2ms\n",
      "Speed: 4.7ms preprocess, 253.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 258.1ms\n",
      "Speed: 4.1ms preprocess, 258.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 262.4ms\n",
      "Speed: 5.8ms preprocess, 262.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 260.6ms\n",
      "Speed: 6.2ms preprocess, 260.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 234.2ms\n",
      "Speed: 3.3ms preprocess, 234.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 275.1ms\n",
      "Speed: 4.5ms preprocess, 275.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 272.8ms\n",
      "Speed: 3.7ms preprocess, 272.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 5 persons, 263.9ms\n",
      "Speed: 4.9ms preprocess, 263.9ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 252.7ms\n",
      "Speed: 4.9ms preprocess, 252.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 218.7ms\n",
      "Speed: 3.2ms preprocess, 218.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 222.7ms\n",
      "Speed: 2.6ms preprocess, 222.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 244.7ms\n",
      "Speed: 3.0ms preprocess, 244.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 221.3ms\n",
      "Speed: 5.3ms preprocess, 221.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 214.8ms\n",
      "Speed: 2.7ms preprocess, 214.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 239.7ms\n",
      "Speed: 3.1ms preprocess, 239.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 264.0ms\n",
      "Speed: 3.2ms preprocess, 264.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 263.6ms\n",
      "Speed: 5.5ms preprocess, 263.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 214.2ms\n",
      "Speed: 4.3ms preprocess, 214.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 270.6ms\n",
      "Speed: 3.6ms preprocess, 270.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 249.2ms\n",
      "Speed: 5.2ms preprocess, 249.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 249.6ms\n",
      "Speed: 2.0ms preprocess, 249.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 242.6ms\n",
      "Speed: 2.6ms preprocess, 242.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 222.3ms\n",
      "Speed: 3.1ms preprocess, 222.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 166.1ms\n",
      "Speed: 4.5ms preprocess, 166.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 199.3ms\n",
      "Speed: 2.0ms preprocess, 199.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 227.8ms\n",
      "Speed: 3.0ms preprocess, 227.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 195.1ms\n",
      "Speed: 2.0ms preprocess, 195.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 213.9ms\n",
      "Speed: 4.0ms preprocess, 213.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 195.5ms\n",
      "Speed: 3.0ms preprocess, 195.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 210.7ms\n",
      "Speed: 2.2ms preprocess, 210.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 232.8ms\n",
      "Speed: 2.5ms preprocess, 232.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 193.0ms\n",
      "Speed: 5.6ms preprocess, 193.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 192.5ms\n",
      "Speed: 2.5ms preprocess, 192.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 217.7ms\n",
      "Speed: 3.5ms preprocess, 217.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 238.1ms\n",
      "Speed: 3.6ms preprocess, 238.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 261.1ms\n",
      "Speed: 5.0ms preprocess, 261.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 231.9ms\n",
      "Speed: 3.1ms preprocess, 231.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 400.4ms\n",
      "Speed: 5.7ms preprocess, 400.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 323.4ms\n",
      "Speed: 3.6ms preprocess, 323.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 283.6ms\n",
      "Speed: 4.0ms preprocess, 283.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 267.5ms\n",
      "Speed: 4.7ms preprocess, 267.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 446.6ms\n",
      "Speed: 4.1ms preprocess, 446.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 213.5ms\n",
      "Speed: 3.7ms preprocess, 213.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 132.4ms\n",
      "Speed: 2.3ms preprocess, 132.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 205.7ms\n",
      "Speed: 5.5ms preprocess, 205.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 212.1ms\n",
      "Speed: 3.0ms preprocess, 212.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 220.9ms\n",
      "Speed: 1.0ms preprocess, 220.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 238.0ms\n",
      "Speed: 3.9ms preprocess, 238.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 256.5ms\n",
      "Speed: 5.0ms preprocess, 256.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 201.9ms\n",
      "Speed: 2.0ms preprocess, 201.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 236.0ms\n",
      "Speed: 4.5ms preprocess, 236.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 258.2ms\n",
      "Speed: 2.7ms preprocess, 258.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 225.7ms\n",
      "Speed: 4.4ms preprocess, 225.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 273.5ms\n",
      "Speed: 2.9ms preprocess, 273.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 221.2ms\n",
      "Speed: 3.0ms preprocess, 221.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 259.8ms\n",
      "Speed: 6.3ms preprocess, 259.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 267.8ms\n",
      "Speed: 2.0ms preprocess, 267.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 231.4ms\n",
      "Speed: 3.1ms preprocess, 231.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 258.4ms\n",
      "Speed: 6.0ms preprocess, 258.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 233.2ms\n",
      "Speed: 3.5ms preprocess, 233.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 151.6ms\n",
      "Speed: 2.7ms preprocess, 151.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 209.5ms\n",
      "Speed: 2.7ms preprocess, 209.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 216.0ms\n",
      "Speed: 5.5ms preprocess, 216.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 192.1ms\n",
      "Speed: 3.0ms preprocess, 192.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 270.7ms\n",
      "Speed: 3.6ms preprocess, 270.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 251.0ms\n",
      "Speed: 3.0ms preprocess, 251.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 257.9ms\n",
      "Speed: 4.6ms preprocess, 257.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 243.4ms\n",
      "Speed: 4.3ms preprocess, 243.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 278.8ms\n",
      "Speed: 4.6ms preprocess, 278.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 226.5ms\n",
      "Speed: 4.0ms preprocess, 226.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 240.8ms\n",
      "Speed: 3.0ms preprocess, 240.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 233.9ms\n",
      "Speed: 3.0ms preprocess, 233.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 261.3ms\n",
      "Speed: 4.6ms preprocess, 261.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 242.8ms\n",
      "Speed: 3.9ms preprocess, 242.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 258.7ms\n",
      "Speed: 3.6ms preprocess, 258.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 223.4ms\n",
      "Speed: 3.0ms preprocess, 223.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 238.1ms\n",
      "Speed: 4.5ms preprocess, 238.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 260.2ms\n",
      "Speed: 3.2ms preprocess, 260.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 259.3ms\n",
      "Speed: 3.3ms preprocess, 259.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 253.8ms\n",
      "Speed: 3.6ms preprocess, 253.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 236.4ms\n",
      "Speed: 3.4ms preprocess, 236.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 188.1ms\n",
      "Speed: 2.9ms preprocess, 188.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 249.5ms\n",
      "Speed: 3.8ms preprocess, 249.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 206.3ms\n",
      "Speed: 2.5ms preprocess, 206.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 227.5ms\n",
      "Speed: 4.6ms preprocess, 227.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 263.8ms\n",
      "Speed: 3.6ms preprocess, 263.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 254.5ms\n",
      "Speed: 2.9ms preprocess, 254.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 253.8ms\n",
      "Speed: 5.0ms preprocess, 253.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 207.2ms\n",
      "Speed: 3.0ms preprocess, 207.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 156.2ms\n",
      "Speed: 2.1ms preprocess, 156.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 231.6ms\n",
      "Speed: 3.0ms preprocess, 231.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 216.0ms\n",
      "Speed: 3.0ms preprocess, 216.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 260.8ms\n",
      "Speed: 3.9ms preprocess, 260.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 197.4ms\n",
      "Speed: 2.6ms preprocess, 197.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 232.4ms\n",
      "Speed: 4.0ms preprocess, 232.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 207.7ms\n",
      "Speed: 2.6ms preprocess, 207.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 200.9ms\n",
      "Speed: 2.0ms preprocess, 200.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 225.7ms\n",
      "Speed: 3.0ms preprocess, 225.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 247.9ms\n",
      "Speed: 4.6ms preprocess, 247.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 259.7ms\n",
      "Speed: 3.6ms preprocess, 259.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 246.2ms\n",
      "Speed: 3.4ms preprocess, 246.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 262.9ms\n",
      "Speed: 5.7ms preprocess, 262.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 254.2ms\n",
      "Speed: 2.7ms preprocess, 254.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 248.1ms\n",
      "Speed: 2.0ms preprocess, 248.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 241.9ms\n",
      "Speed: 3.9ms preprocess, 241.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 218.6ms\n",
      "Speed: 3.0ms preprocess, 218.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 254.6ms\n",
      "Speed: 2.1ms preprocess, 254.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 241.6ms\n",
      "Speed: 6.9ms preprocess, 241.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 207.6ms\n",
      "Speed: 2.9ms preprocess, 207.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 248.6ms\n",
      "Speed: 2.9ms preprocess, 248.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 245.5ms\n",
      "Speed: 6.5ms preprocess, 245.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 125.7ms\n",
      "Speed: 3.0ms preprocess, 125.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 196.1ms\n",
      "Speed: 2.0ms preprocess, 196.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 223.2ms\n",
      "Speed: 2.6ms preprocess, 223.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 260.9ms\n",
      "Speed: 4.0ms preprocess, 260.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 246.6ms\n",
      "Speed: 3.1ms preprocess, 246.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 252.4ms\n",
      "Speed: 2.0ms preprocess, 252.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 255.0ms\n",
      "Speed: 3.7ms preprocess, 255.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 258.0ms\n",
      "Speed: 4.8ms preprocess, 258.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 245.2ms\n",
      "Speed: 5.0ms preprocess, 245.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 253.2ms\n",
      "Speed: 5.6ms preprocess, 253.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 247.9ms\n",
      "Speed: 2.9ms preprocess, 247.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 258.6ms\n",
      "Speed: 3.8ms preprocess, 258.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 239.7ms\n",
      "Speed: 5.2ms preprocess, 239.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 238.9ms\n",
      "Speed: 3.8ms preprocess, 238.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 263.1ms\n",
      "Speed: 3.0ms preprocess, 263.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 254.8ms\n",
      "Speed: 5.2ms preprocess, 254.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 250.7ms\n",
      "Speed: 2.6ms preprocess, 250.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 232.7ms\n",
      "Speed: 3.2ms preprocess, 232.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 254.7ms\n",
      "Speed: 3.9ms preprocess, 254.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 244.6ms\n",
      "Speed: 3.0ms preprocess, 244.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 155.3ms\n",
      "Speed: 4.5ms preprocess, 155.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 249.5ms\n",
      "Speed: 5.2ms preprocess, 249.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 274.3ms\n",
      "Speed: 2.9ms preprocess, 274.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 251.2ms\n",
      "Speed: 3.0ms preprocess, 251.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 248.0ms\n",
      "Speed: 4.2ms preprocess, 248.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 221.9ms\n",
      "Speed: 2.5ms preprocess, 221.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 244.1ms\n",
      "Speed: 3.7ms preprocess, 244.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 227.9ms\n",
      "Speed: 3.7ms preprocess, 227.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 266.4ms\n",
      "Speed: 3.4ms preprocess, 266.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 257.1ms\n",
      "Speed: 3.0ms preprocess, 257.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 259.2ms\n",
      "Speed: 6.6ms preprocess, 259.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 231.0ms\n",
      "Speed: 3.0ms preprocess, 231.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 251.2ms\n",
      "Speed: 3.8ms preprocess, 251.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 221.2ms\n",
      "Speed: 3.1ms preprocess, 221.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 236.8ms\n",
      "Speed: 3.0ms preprocess, 236.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 257.3ms\n",
      "Speed: 4.1ms preprocess, 257.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 262.4ms\n",
      "Speed: 6.7ms preprocess, 262.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 212.5ms\n",
      "Speed: 3.0ms preprocess, 212.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 254.6ms\n",
      "Speed: 4.0ms preprocess, 254.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 250.9ms\n",
      "Speed: 6.6ms preprocess, 250.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 255.4ms\n",
      "Speed: 3.1ms preprocess, 255.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 254.0ms\n",
      "Speed: 2.9ms preprocess, 254.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 292.8ms\n",
      "Speed: 6.7ms preprocess, 292.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 216.9ms\n",
      "Speed: 2.5ms preprocess, 216.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 260.1ms\n",
      "Speed: 4.0ms preprocess, 260.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 269.7ms\n",
      "Speed: 4.0ms preprocess, 269.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 259.2ms\n",
      "Speed: 2.5ms preprocess, 259.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 268.9ms\n",
      "Speed: 4.1ms preprocess, 268.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 244.5ms\n",
      "Speed: 5.2ms preprocess, 244.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 261.8ms\n",
      "Speed: 3.0ms preprocess, 261.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 243.8ms\n",
      "Speed: 3.0ms preprocess, 243.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 250.0ms\n",
      "Speed: 4.0ms preprocess, 250.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 232.8ms\n",
      "Speed: 3.0ms preprocess, 232.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 224.3ms\n",
      "Speed: 3.0ms preprocess, 224.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 245.8ms\n",
      "Speed: 5.0ms preprocess, 245.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 258.9ms\n",
      "Speed: 3.6ms preprocess, 258.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 243.2ms\n",
      "Speed: 4.0ms preprocess, 243.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 227.5ms\n",
      "Speed: 5.5ms preprocess, 227.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 228.0ms\n",
      "Speed: 2.6ms preprocess, 228.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 207.6ms\n",
      "Speed: 2.9ms preprocess, 207.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 236.6ms\n",
      "Speed: 4.0ms preprocess, 236.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 263.1ms\n",
      "Speed: 3.6ms preprocess, 263.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 201.8ms\n",
      "Speed: 2.0ms preprocess, 201.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 222.9ms\n",
      "Speed: 4.0ms preprocess, 222.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 224.0ms\n",
      "Speed: 4.0ms preprocess, 224.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 163.4ms\n",
      "Speed: 2.5ms preprocess, 163.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 236.5ms\n",
      "Speed: 3.0ms preprocess, 236.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 240.2ms\n",
      "Speed: 4.0ms preprocess, 240.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 242.1ms\n",
      "Speed: 2.0ms preprocess, 242.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 257.5ms\n",
      "Speed: 4.6ms preprocess, 257.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 250.8ms\n",
      "Speed: 6.9ms preprocess, 250.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 264.6ms\n",
      "Speed: 3.7ms preprocess, 264.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 241.5ms\n",
      "Speed: 3.0ms preprocess, 241.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 222.3ms\n",
      "Speed: 4.6ms preprocess, 222.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 242.3ms\n",
      "Speed: 3.2ms preprocess, 242.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 262.6ms\n",
      "Speed: 4.0ms preprocess, 262.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 262.5ms\n",
      "Speed: 4.9ms preprocess, 262.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 248.9ms\n",
      "Speed: 2.0ms preprocess, 248.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 238.4ms\n",
      "Speed: 3.5ms preprocess, 238.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 243.8ms\n",
      "Speed: 3.7ms preprocess, 243.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 265.6ms\n",
      "Speed: 3.0ms preprocess, 265.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 257.8ms\n",
      "Speed: 2.5ms preprocess, 257.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 255.8ms\n",
      "Speed: 4.6ms preprocess, 255.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 250.2ms\n",
      "Speed: 4.0ms preprocess, 250.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 229.1ms\n",
      "Speed: 3.2ms preprocess, 229.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 254.4ms\n",
      "Speed: 3.6ms preprocess, 254.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 270.5ms\n",
      "Speed: 3.9ms preprocess, 270.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 219.2ms\n",
      "Speed: 3.5ms preprocess, 219.2ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 242.5ms\n",
      "Speed: 4.2ms preprocess, 242.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 267.1ms\n",
      "Speed: 2.9ms preprocess, 267.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 264.4ms\n",
      "Speed: 3.5ms preprocess, 264.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 234.2ms\n",
      "Speed: 4.0ms preprocess, 234.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 260.0ms\n",
      "Speed: 3.0ms preprocess, 260.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 227.5ms\n",
      "Speed: 2.0ms preprocess, 227.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 253.0ms\n",
      "Speed: 5.1ms preprocess, 253.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 235.1ms\n",
      "Speed: 2.9ms preprocess, 235.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 237.3ms\n",
      "Speed: 3.0ms preprocess, 237.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 263.2ms\n",
      "Speed: 6.7ms preprocess, 263.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 253.3ms\n",
      "Speed: 3.0ms preprocess, 253.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 253.8ms\n",
      "Speed: 2.0ms preprocess, 253.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 237.6ms\n",
      "Speed: 5.9ms preprocess, 237.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 258.6ms\n",
      "Speed: 3.0ms preprocess, 258.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 206.0ms\n",
      "Speed: 3.0ms preprocess, 206.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 236.7ms\n",
      "Speed: 4.6ms preprocess, 236.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 253.9ms\n",
      "Speed: 2.9ms preprocess, 253.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 251.2ms\n",
      "Speed: 3.7ms preprocess, 251.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 243.2ms\n",
      "Speed: 3.8ms preprocess, 243.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 222.2ms\n",
      "Speed: 1.9ms preprocess, 222.2ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 260.5ms\n",
      "Speed: 3.5ms preprocess, 260.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 232.2ms\n",
      "Speed: 4.4ms preprocess, 232.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 221.1ms\n",
      "Speed: 3.0ms preprocess, 221.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 223.2ms\n",
      "Speed: 3.0ms preprocess, 223.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 270.3ms\n",
      "Speed: 6.3ms preprocess, 270.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 261.2ms\n",
      "Speed: 2.8ms preprocess, 261.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 257.7ms\n",
      "Speed: 3.3ms preprocess, 257.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 230.8ms\n",
      "Speed: 3.9ms preprocess, 230.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 225.6ms\n",
      "Speed: 2.0ms preprocess, 225.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 250.8ms\n",
      "Speed: 2.0ms preprocess, 250.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 248.8ms\n",
      "Speed: 4.6ms preprocess, 248.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 268.9ms\n",
      "Speed: 4.0ms preprocess, 268.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 258.5ms\n",
      "Speed: 3.5ms preprocess, 258.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 216.3ms\n",
      "Speed: 3.7ms preprocess, 216.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 238.1ms\n",
      "Speed: 3.0ms preprocess, 238.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 239.5ms\n",
      "Speed: 3.0ms preprocess, 239.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 227.0ms\n",
      "Speed: 4.8ms preprocess, 227.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 241.5ms\n",
      "Speed: 2.9ms preprocess, 241.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 251.7ms\n",
      "Speed: 2.9ms preprocess, 251.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 238.3ms\n",
      "Speed: 3.5ms preprocess, 238.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 222.9ms\n",
      "Speed: 3.4ms preprocess, 222.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 256.1ms\n",
      "Speed: 2.9ms preprocess, 256.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 231.7ms\n",
      "Speed: 4.6ms preprocess, 231.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 222.4ms\n",
      "Speed: 1.9ms preprocess, 222.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 247.6ms\n",
      "Speed: 2.3ms preprocess, 247.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 259.4ms\n",
      "Speed: 4.0ms preprocess, 259.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 256.0ms\n",
      "Speed: 3.9ms preprocess, 256.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 220.6ms\n",
      "Speed: 2.0ms preprocess, 220.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 219.4ms\n",
      "Speed: 4.6ms preprocess, 219.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 264.6ms\n",
      "Speed: 4.5ms preprocess, 264.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 223.0ms\n",
      "Speed: 3.6ms preprocess, 223.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 222.5ms\n",
      "Speed: 4.9ms preprocess, 222.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 190.7ms\n",
      "Speed: 1.9ms preprocess, 190.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 222.2ms\n",
      "Speed: 2.3ms preprocess, 222.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 215.2ms\n",
      "Speed: 4.0ms preprocess, 215.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 260.1ms\n",
      "Speed: 3.0ms preprocess, 260.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 234.9ms\n",
      "Speed: 2.0ms preprocess, 234.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 254.1ms\n",
      "Speed: 6.5ms preprocess, 254.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 206.9ms\n",
      "Speed: 2.8ms preprocess, 206.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 258.9ms\n",
      "Speed: 3.6ms preprocess, 258.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 265.7ms\n",
      "Speed: 5.0ms preprocess, 265.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 241.1ms\n",
      "Speed: 2.0ms preprocess, 241.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 264.3ms\n",
      "Speed: 2.0ms preprocess, 264.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 247.7ms\n",
      "Speed: 3.5ms preprocess, 247.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 244.3ms\n",
      "Speed: 2.3ms preprocess, 244.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 262.3ms\n",
      "Speed: 3.3ms preprocess, 262.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 255.5ms\n",
      "Speed: 6.0ms preprocess, 255.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 250.9ms\n",
      "Speed: 2.5ms preprocess, 250.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 272.3ms\n",
      "Speed: 2.9ms preprocess, 272.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 259.8ms\n",
      "Speed: 4.0ms preprocess, 259.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 252.8ms\n",
      "Speed: 3.0ms preprocess, 252.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 265.7ms\n",
      "Speed: 3.6ms preprocess, 265.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 251.9ms\n",
      "Speed: 4.5ms preprocess, 251.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 262.0ms\n",
      "Speed: 3.0ms preprocess, 262.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 259.7ms\n",
      "Speed: 2.6ms preprocess, 259.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 255.5ms\n",
      "Speed: 4.1ms preprocess, 255.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 263.4ms\n",
      "Speed: 5.0ms preprocess, 263.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 216.9ms\n",
      "Speed: 2.8ms preprocess, 216.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 254.2ms\n",
      "Speed: 4.2ms preprocess, 254.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 232.8ms\n",
      "Speed: 2.7ms preprocess, 232.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 268.7ms\n",
      "Speed: 3.5ms preprocess, 268.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 216.4ms\n",
      "Speed: 4.5ms preprocess, 216.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 245.1ms\n",
      "Speed: 2.6ms preprocess, 245.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 229.8ms\n",
      "Speed: 2.4ms preprocess, 229.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 270.0ms\n",
      "Speed: 5.9ms preprocess, 270.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 247.5ms\n",
      "Speed: 2.1ms preprocess, 247.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 263.3ms\n",
      "Speed: 3.0ms preprocess, 263.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 265.5ms\n",
      "Speed: 4.7ms preprocess, 265.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 233.2ms\n",
      "Speed: 3.0ms preprocess, 233.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 265.1ms\n",
      "Speed: 3.6ms preprocess, 265.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 264.2ms\n",
      "Speed: 5.6ms preprocess, 264.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 242.1ms\n",
      "Speed: 2.2ms preprocess, 242.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 219.7ms\n",
      "Speed: 2.6ms preprocess, 219.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 219.0ms\n",
      "Speed: 3.0ms preprocess, 219.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 240.3ms\n",
      "Speed: 3.2ms preprocess, 240.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 216.4ms\n",
      "Speed: 3.1ms preprocess, 216.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 261.2ms\n",
      "Speed: 5.0ms preprocess, 261.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 262.4ms\n",
      "Speed: 2.8ms preprocess, 262.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 257.8ms\n",
      "Speed: 2.9ms preprocess, 257.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 260.7ms\n",
      "Speed: 6.7ms preprocess, 260.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 244.9ms\n",
      "Speed: 4.6ms preprocess, 244.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 227.6ms\n",
      "Speed: 2.8ms preprocess, 227.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 239.3ms\n",
      "Speed: 4.3ms preprocess, 239.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 234.5ms\n",
      "Speed: 3.0ms preprocess, 234.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 241.6ms\n",
      "Speed: 3.6ms preprocess, 241.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 227.2ms\n",
      "Speed: 4.6ms preprocess, 227.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 211.1ms\n",
      "Speed: 2.2ms preprocess, 211.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 234.6ms\n",
      "Speed: 1.9ms preprocess, 234.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 208.6ms\n",
      "Speed: 2.0ms preprocess, 208.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 248.8ms\n",
      "Speed: 5.7ms preprocess, 248.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 250.6ms\n",
      "Speed: 1.8ms preprocess, 250.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 238.8ms\n",
      "Speed: 2.7ms preprocess, 238.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 222.4ms\n",
      "Speed: 4.0ms preprocess, 222.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 246.0ms\n",
      "Speed: 3.0ms preprocess, 246.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 266.7ms\n",
      "Speed: 3.9ms preprocess, 266.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 236.9ms\n",
      "Speed: 6.6ms preprocess, 236.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 235.4ms\n",
      "Speed: 2.5ms preprocess, 235.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 250.8ms\n",
      "Speed: 2.9ms preprocess, 250.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 263.4ms\n",
      "Speed: 4.7ms preprocess, 263.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 228.0ms\n",
      "Speed: 3.1ms preprocess, 228.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 253.5ms\n",
      "Speed: 2.0ms preprocess, 253.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 257.5ms\n",
      "Speed: 5.6ms preprocess, 257.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 237.0ms\n",
      "Speed: 2.9ms preprocess, 237.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 223.0ms\n",
      "Speed: 2.9ms preprocess, 223.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 256.4ms\n",
      "Speed: 4.0ms preprocess, 256.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 236.6ms\n",
      "Speed: 2.9ms preprocess, 236.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 242.6ms\n",
      "Speed: 3.8ms preprocess, 242.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 135.4ms\n",
      "Speed: 4.6ms preprocess, 135.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 241.9ms\n",
      "Speed: 4.0ms preprocess, 241.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 271.2ms\n",
      "Speed: 4.3ms preprocess, 271.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 259.7ms\n",
      "Speed: 5.0ms preprocess, 259.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 243.4ms\n",
      "Speed: 4.6ms preprocess, 243.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 269.8ms\n",
      "Speed: 4.7ms preprocess, 269.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 235.5ms\n",
      "Speed: 4.3ms preprocess, 235.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 257.1ms\n",
      "Speed: 2.1ms preprocess, 257.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 243.4ms\n",
      "Speed: 1.8ms preprocess, 243.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 246.5ms\n",
      "Speed: 3.1ms preprocess, 246.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 240.9ms\n",
      "Speed: 3.0ms preprocess, 240.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 244.5ms\n",
      "Speed: 2.9ms preprocess, 244.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 260.1ms\n",
      "Speed: 5.2ms preprocess, 260.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 250.0ms\n",
      "Speed: 2.0ms preprocess, 250.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 254.5ms\n",
      "Speed: 2.0ms preprocess, 254.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 267.0ms\n",
      "Speed: 5.0ms preprocess, 267.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 191.2ms\n",
      "Speed: 4.0ms preprocess, 191.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 223.3ms\n",
      "Speed: 2.2ms preprocess, 223.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 256.5ms\n",
      "Speed: 4.6ms preprocess, 256.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 264.3ms\n",
      "Speed: 3.6ms preprocess, 264.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 219.8ms\n",
      "Speed: 2.0ms preprocess, 219.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 219.7ms\n",
      "Speed: 5.0ms preprocess, 219.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 229.1ms\n",
      "Speed: 2.5ms preprocess, 229.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 251.2ms\n",
      "Speed: 2.9ms preprocess, 251.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 244.7ms\n",
      "Speed: 4.5ms preprocess, 244.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 239.9ms\n",
      "Speed: 2.8ms preprocess, 239.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 251.9ms\n",
      "Speed: 4.0ms preprocess, 251.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 244.2ms\n",
      "Speed: 4.6ms preprocess, 244.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 267.2ms\n",
      "Speed: 4.1ms preprocess, 267.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 230.4ms\n",
      "Speed: 2.5ms preprocess, 230.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 255.6ms\n",
      "Speed: 4.0ms preprocess, 255.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 289.9ms\n",
      "Speed: 4.5ms preprocess, 289.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 240.6ms\n",
      "Speed: 2.5ms preprocess, 240.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 257.7ms\n",
      "Speed: 6.6ms preprocess, 257.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 232.1ms\n",
      "Speed: 4.9ms preprocess, 232.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 223.2ms\n",
      "Speed: 2.0ms preprocess, 223.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 273.0ms\n",
      "Speed: 6.7ms preprocess, 273.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 248.8ms\n",
      "Speed: 3.5ms preprocess, 248.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 259.3ms\n",
      "Speed: 3.1ms preprocess, 259.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 259.3ms\n",
      "Speed: 4.6ms preprocess, 259.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 250.7ms\n",
      "Speed: 3.2ms preprocess, 250.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 263.4ms\n",
      "Speed: 5.6ms preprocess, 263.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 241.2ms\n",
      "Speed: 3.9ms preprocess, 241.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 258.1ms\n",
      "Speed: 3.6ms preprocess, 258.1ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 253.1ms\n",
      "Speed: 2.9ms preprocess, 253.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 249.9ms\n",
      "Speed: 5.1ms preprocess, 249.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 262.4ms\n",
      "Speed: 3.3ms preprocess, 262.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 230.2ms\n",
      "Speed: 2.7ms preprocess, 230.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 226.7ms\n",
      "Speed: 3.6ms preprocess, 226.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 238.5ms\n",
      "Speed: 2.0ms preprocess, 238.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 257.2ms\n",
      "Speed: 3.0ms preprocess, 257.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 235.6ms\n",
      "Speed: 4.3ms preprocess, 235.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 227.2ms\n",
      "Speed: 3.0ms preprocess, 227.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 245.5ms\n",
      "Speed: 2.4ms preprocess, 245.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 240.7ms\n",
      "Speed: 5.0ms preprocess, 240.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 237.7ms\n",
      "Speed: 2.6ms preprocess, 237.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 256.4ms\n",
      "Speed: 3.6ms preprocess, 256.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 231.1ms\n",
      "Speed: 3.7ms preprocess, 231.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 265.1ms\n",
      "Speed: 3.9ms preprocess, 265.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 247.0ms\n",
      "Speed: 3.0ms preprocess, 247.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 262.4ms\n",
      "Speed: 5.7ms preprocess, 262.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 255.8ms\n",
      "Speed: 3.0ms preprocess, 255.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 250.1ms\n",
      "Speed: 3.0ms preprocess, 250.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 246.5ms\n",
      "Speed: 3.6ms preprocess, 246.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 243.5ms\n",
      "Speed: 2.4ms preprocess, 243.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 237.6ms\n",
      "Speed: 3.0ms preprocess, 237.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 259.8ms\n",
      "Speed: 5.7ms preprocess, 259.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 264.7ms\n",
      "Speed: 3.0ms preprocess, 264.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 262.0ms\n",
      "Speed: 3.4ms preprocess, 262.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 229.4ms\n",
      "Speed: 3.7ms preprocess, 229.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 225.5ms\n",
      "Speed: 2.0ms preprocess, 225.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 237.1ms\n",
      "Speed: 2.5ms preprocess, 237.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 246.6ms\n",
      "Speed: 4.6ms preprocess, 246.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 260.8ms\n",
      "Speed: 3.9ms preprocess, 260.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 265.2ms\n",
      "Speed: 2.9ms preprocess, 265.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 218.6ms\n",
      "Speed: 5.4ms preprocess, 218.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 250.6ms\n",
      "Speed: 3.1ms preprocess, 250.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 224.2ms\n",
      "Speed: 3.0ms preprocess, 224.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 250.7ms\n",
      "Speed: 4.5ms preprocess, 250.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 245.6ms\n",
      "Speed: 3.0ms preprocess, 245.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 207.2ms\n",
      "Speed: 3.0ms preprocess, 207.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 257.5ms\n",
      "Speed: 4.1ms preprocess, 257.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 227.3ms\n",
      "Speed: 3.0ms preprocess, 227.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 233.1ms\n",
      "Speed: 2.6ms preprocess, 233.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 232.2ms\n",
      "Speed: 4.3ms preprocess, 232.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 256.9ms\n",
      "Speed: 3.2ms preprocess, 256.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 223.0ms\n",
      "Speed: 3.6ms preprocess, 223.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 278.8ms\n",
      "Speed: 4.9ms preprocess, 278.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 253.3ms\n",
      "Speed: 3.0ms preprocess, 253.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 248.8ms\n",
      "Speed: 3.6ms preprocess, 248.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 258.0ms\n",
      "Speed: 3.7ms preprocess, 258.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 245.1ms\n",
      "Speed: 3.0ms preprocess, 245.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 244.1ms\n",
      "Speed: 2.7ms preprocess, 244.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 229.9ms\n",
      "Speed: 5.4ms preprocess, 229.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 226.6ms\n",
      "Speed: 1.9ms preprocess, 226.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 225.9ms\n",
      "Speed: 1.9ms preprocess, 225.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 251.0ms\n",
      "Speed: 4.0ms preprocess, 251.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 244.3ms\n",
      "Speed: 3.5ms preprocess, 244.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 255.7ms\n",
      "Speed: 2.1ms preprocess, 255.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 240.0ms\n",
      "Speed: 3.0ms preprocess, 240.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 229.4ms\n",
      "Speed: 3.0ms preprocess, 229.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 243.5ms\n",
      "Speed: 2.8ms preprocess, 243.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 240.8ms\n",
      "Speed: 5.0ms preprocess, 240.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 252.8ms\n",
      "Speed: 2.0ms preprocess, 252.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 252.0ms\n",
      "Speed: 2.6ms preprocess, 252.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 189.7ms\n",
      "Speed: 4.0ms preprocess, 189.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 262.0ms\n",
      "Speed: 4.5ms preprocess, 262.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 203.3ms\n",
      "Speed: 2.0ms preprocess, 203.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 222.5ms\n",
      "Speed: 4.0ms preprocess, 222.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 215.9ms\n",
      "Speed: 2.4ms preprocess, 215.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 270.4ms\n",
      "Speed: 3.0ms preprocess, 270.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 224.7ms\n",
      "Speed: 3.6ms preprocess, 224.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 244.1ms\n",
      "Speed: 2.3ms preprocess, 244.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 246.9ms\n",
      "Speed: 3.0ms preprocess, 246.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 267.6ms\n",
      "Speed: 4.9ms preprocess, 267.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 261.0ms\n",
      "Speed: 2.9ms preprocess, 261.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 254.9ms\n",
      "Speed: 3.1ms preprocess, 254.9ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 240.3ms\n",
      "Speed: 4.0ms preprocess, 240.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 229.0ms\n",
      "Speed: 3.0ms preprocess, 229.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 239.9ms\n",
      "Speed: 5.1ms preprocess, 239.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 206.6ms\n",
      "Speed: 3.7ms preprocess, 206.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 212.4ms\n",
      "Speed: 2.9ms preprocess, 212.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 245.7ms\n",
      "Speed: 3.0ms preprocess, 245.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 263.3ms\n",
      "Speed: 5.6ms preprocess, 263.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 264.2ms\n",
      "Speed: 3.9ms preprocess, 264.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 235.4ms\n",
      "Speed: 4.0ms preprocess, 235.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 205.7ms\n",
      "Speed: 3.0ms preprocess, 205.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 237.0ms\n",
      "Speed: 3.0ms preprocess, 237.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 198.2ms\n",
      "Speed: 2.0ms preprocess, 198.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 205.8ms\n",
      "Speed: 3.7ms preprocess, 205.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 229.6ms\n",
      "Speed: 2.8ms preprocess, 229.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 (no detections), 265.9ms\n",
      "Speed: 3.5ms preprocess, 265.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 264.7ms\n",
      "Speed: 4.5ms preprocess, 264.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 231.7ms\n",
      "Speed: 5.6ms preprocess, 231.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 243.6ms\n",
      "Speed: 4.1ms preprocess, 243.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 237.3ms\n",
      "Speed: 5.7ms preprocess, 237.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 237.2ms\n",
      "Speed: 4.0ms preprocess, 237.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 238.6ms\n",
      "Speed: 4.6ms preprocess, 238.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 224.2ms\n",
      "Speed: 3.8ms preprocess, 224.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 234.9ms\n",
      "Speed: 4.6ms preprocess, 234.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 230.7ms\n",
      "Speed: 4.6ms preprocess, 230.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 224.5ms\n",
      "Speed: 4.6ms preprocess, 224.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 257.3ms\n",
      "Speed: 4.7ms preprocess, 257.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 264.5ms\n",
      "Speed: 4.4ms preprocess, 264.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 250.5ms\n",
      "Speed: 5.6ms preprocess, 250.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 269.3ms\n",
      "Speed: 5.0ms preprocess, 269.3ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 233.5ms\n",
      "Speed: 4.0ms preprocess, 233.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 221.8ms\n",
      "Speed: 4.0ms preprocess, 221.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 234.2ms\n",
      "Speed: 5.0ms preprocess, 234.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 229.2ms\n",
      "Speed: 5.0ms preprocess, 229.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 219.0ms\n",
      "Speed: 5.1ms preprocess, 219.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 231.0ms\n",
      "Speed: 4.5ms preprocess, 231.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 227.4ms\n",
      "Speed: 5.2ms preprocess, 227.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 259.4ms\n",
      "Speed: 4.0ms preprocess, 259.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 209.8ms\n",
      "Speed: 4.3ms preprocess, 209.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 230.2ms\n",
      "Speed: 4.0ms preprocess, 230.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 223.9ms\n",
      "Speed: 3.9ms preprocess, 223.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 229.8ms\n",
      "Speed: 4.1ms preprocess, 229.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 224.1ms\n",
      "Speed: 5.1ms preprocess, 224.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 200.1ms\n",
      "Speed: 3.1ms preprocess, 200.1ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 232.4ms\n",
      "Speed: 4.6ms preprocess, 232.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 219.2ms\n",
      "Speed: 4.6ms preprocess, 219.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 257.2ms\n",
      "Speed: 4.3ms preprocess, 257.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 247.3ms\n",
      "Speed: 5.2ms preprocess, 247.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 238.0ms\n",
      "Speed: 4.2ms preprocess, 238.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 252.8ms\n",
      "Speed: 4.5ms preprocess, 252.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 247.2ms\n",
      "Speed: 4.0ms preprocess, 247.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 244.5ms\n",
      "Speed: 4.6ms preprocess, 244.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 232.1ms\n",
      "Speed: 4.0ms preprocess, 232.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 246.7ms\n",
      "Speed: 4.6ms preprocess, 246.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 239.8ms\n",
      "Speed: 3.9ms preprocess, 239.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 253.4ms\n",
      "Speed: 3.6ms preprocess, 253.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 179.5ms\n",
      "Speed: 5.6ms preprocess, 179.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 133.1ms\n",
      "Speed: 3.6ms preprocess, 133.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 147.9ms\n",
      "Speed: 2.7ms preprocess, 147.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 140.8ms\n",
      "Speed: 2.0ms preprocess, 140.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 189.7ms\n",
      "Speed: 2.6ms preprocess, 189.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 223.8ms\n",
      "Speed: 4.0ms preprocess, 223.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 239.5ms\n",
      "Speed: 5.2ms preprocess, 239.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 223.1ms\n",
      "Speed: 4.6ms preprocess, 223.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 248.5ms\n",
      "Speed: 3.8ms preprocess, 248.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 247.8ms\n",
      "Speed: 4.6ms preprocess, 247.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 244.5ms\n",
      "Speed: 5.1ms preprocess, 244.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 262.2ms\n",
      "Speed: 5.2ms preprocess, 262.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 249.3ms\n",
      "Speed: 4.0ms preprocess, 249.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 246.3ms\n",
      "Speed: 4.6ms preprocess, 246.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 254.5ms\n",
      "Speed: 5.0ms preprocess, 254.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 244.4ms\n",
      "Speed: 4.0ms preprocess, 244.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 159.4ms\n",
      "Speed: 3.7ms preprocess, 159.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 228.2ms\n",
      "Speed: 5.2ms preprocess, 228.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 235.9ms\n",
      "Speed: 5.0ms preprocess, 235.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 273.5ms\n",
      "Speed: 4.6ms preprocess, 273.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 270.3ms\n",
      "Speed: 4.0ms preprocess, 270.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 263.2ms\n",
      "Speed: 4.8ms preprocess, 263.2ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 258.3ms\n",
      "Speed: 5.0ms preprocess, 258.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 268.2ms\n",
      "Speed: 5.6ms preprocess, 268.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 238.7ms\n",
      "Speed: 4.5ms preprocess, 238.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 272.5ms\n",
      "Speed: 5.0ms preprocess, 272.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 271.6ms\n",
      "Speed: 4.6ms preprocess, 271.6ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 271.0ms\n",
      "Speed: 3.9ms preprocess, 271.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 251.6ms\n",
      "Speed: 4.3ms preprocess, 251.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 283.9ms\n",
      "Speed: 6.0ms preprocess, 283.9ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 287.9ms\n",
      "Speed: 4.0ms preprocess, 287.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 291.5ms\n",
      "Speed: 3.0ms preprocess, 291.5ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 289.7ms\n",
      "Speed: 4.0ms preprocess, 289.7ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 292.8ms\n",
      "Speed: 5.0ms preprocess, 292.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 250.8ms\n",
      "Speed: 4.8ms preprocess, 250.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.0ms\n",
      "Speed: 3.6ms preprocess, 147.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 167.3ms\n",
      "Speed: 3.0ms preprocess, 167.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 179.0ms\n",
      "Speed: 3.0ms preprocess, 179.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 160.8ms\n",
      "Speed: 3.1ms preprocess, 160.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 223.4ms\n",
      "Speed: 3.0ms preprocess, 223.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 259.0ms\n",
      "Speed: 6.1ms preprocess, 259.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 243.6ms\n",
      "Speed: 4.8ms preprocess, 243.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 178.8ms\n",
      "Speed: 4.1ms preprocess, 178.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 262.4ms\n",
      "Speed: 2.9ms preprocess, 262.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 238.8ms\n",
      "Speed: 3.5ms preprocess, 238.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 257.8ms\n",
      "Speed: 3.6ms preprocess, 257.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 795.1ms\n",
      "Speed: 6.6ms preprocess, 795.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1750.4ms\n",
      "Speed: 2.1ms preprocess, 1750.4ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 242.1ms\n",
      "Speed: 5.6ms preprocess, 242.1ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 160.3ms\n",
      "Speed: 4.3ms preprocess, 160.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 222.8ms\n",
      "Speed: 5.0ms preprocess, 222.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 216.6ms\n",
      "Speed: 4.0ms preprocess, 216.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 169.7ms\n",
      "Speed: 3.3ms preprocess, 169.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 256.6ms\n",
      "Speed: 3.4ms preprocess, 256.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 250.6ms\n",
      "Speed: 5.6ms preprocess, 250.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 276.2ms\n",
      "Speed: 4.3ms preprocess, 276.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 295.8ms\n",
      "Speed: 4.6ms preprocess, 295.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 238.3ms\n",
      "Speed: 4.0ms preprocess, 238.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 271.4ms\n",
      "Speed: 5.4ms preprocess, 271.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 283.8ms\n",
      "Speed: 4.7ms preprocess, 283.8ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 277.9ms\n",
      "Speed: 5.1ms preprocess, 277.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 279.9ms\n",
      "Speed: 4.5ms preprocess, 279.9ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 275.1ms\n",
      "Speed: 4.6ms preprocess, 275.1ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 284.1ms\n",
      "Speed: 3.9ms preprocess, 284.1ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 283.7ms\n",
      "Speed: 5.5ms preprocess, 283.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 267.2ms\n",
      "Speed: 4.9ms preprocess, 267.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 258.3ms\n",
      "Speed: 4.7ms preprocess, 258.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 188.1ms\n",
      "Speed: 4.1ms preprocess, 188.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 177.8ms\n",
      "Speed: 2.0ms preprocess, 177.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 235.0ms\n",
      "Speed: 4.4ms preprocess, 235.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 277.8ms\n",
      "Speed: 5.0ms preprocess, 277.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 224.0ms\n",
      "Speed: 3.9ms preprocess, 224.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 241.9ms\n",
      "Speed: 4.3ms preprocess, 241.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 268.1ms\n",
      "Speed: 5.6ms preprocess, 268.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 266.1ms\n",
      "Speed: 4.5ms preprocess, 266.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 242.5ms\n",
      "Speed: 2.9ms preprocess, 242.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 237.6ms\n",
      "Speed: 3.6ms preprocess, 237.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 279.3ms\n",
      "Speed: 5.7ms preprocess, 279.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 251.1ms\n",
      "Speed: 5.5ms preprocess, 251.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 246.1ms\n",
      "Speed: 3.0ms preprocess, 246.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 238.7ms\n",
      "Speed: 4.6ms preprocess, 238.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 268.5ms\n",
      "Speed: 6.0ms preprocess, 268.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 287.0ms\n",
      "Speed: 7.8ms preprocess, 287.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 276.1ms\n",
      "Speed: 4.1ms preprocess, 276.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 277.5ms\n",
      "Speed: 5.5ms preprocess, 277.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 270.6ms\n",
      "Speed: 3.9ms preprocess, 270.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 263.3ms\n",
      "Speed: 5.0ms preprocess, 263.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 264.1ms\n",
      "Speed: 5.4ms preprocess, 264.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 246.6ms\n",
      "Speed: 5.0ms preprocess, 246.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 216.0ms\n",
      "Speed: 4.0ms preprocess, 216.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 254.5ms\n",
      "Speed: 4.5ms preprocess, 254.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 229.7ms\n",
      "Speed: 4.0ms preprocess, 229.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 279.0ms\n",
      "Speed: 5.0ms preprocess, 279.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 268.9ms\n",
      "Speed: 3.7ms preprocess, 268.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 278.2ms\n",
      "Speed: 4.7ms preprocess, 278.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 279.5ms\n",
      "Speed: 4.6ms preprocess, 279.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 279.7ms\n",
      "Speed: 4.9ms preprocess, 279.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 215.6ms\n",
      "Speed: 4.9ms preprocess, 215.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 254.5ms\n",
      "Speed: 4.0ms preprocess, 254.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 243.9ms\n",
      "Speed: 4.0ms preprocess, 243.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 199.6ms\n",
      "Speed: 5.1ms preprocess, 199.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 241.7ms\n",
      "Speed: 3.5ms preprocess, 241.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 264.2ms\n",
      "Speed: 5.8ms preprocess, 264.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 254.1ms\n",
      "Speed: 5.0ms preprocess, 254.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 265.4ms\n",
      "Speed: 4.0ms preprocess, 265.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 254.1ms\n",
      "Speed: 3.9ms preprocess, 254.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 254.8ms\n",
      "Speed: 5.7ms preprocess, 254.8ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 288.9ms\n",
      "Speed: 5.1ms preprocess, 288.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 284.3ms\n",
      "Speed: 4.7ms preprocess, 284.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 282.7ms\n",
      "Speed: 5.1ms preprocess, 282.7ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 245.7ms\n",
      "Speed: 3.6ms preprocess, 245.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 260.0ms\n",
      "Speed: 5.0ms preprocess, 260.0ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 273.1ms\n",
      "Speed: 5.0ms preprocess, 273.1ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 275.6ms\n",
      "Speed: 4.8ms preprocess, 275.6ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 262.1ms\n",
      "Speed: 3.0ms preprocess, 262.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 268.8ms\n",
      "Speed: 4.2ms preprocess, 268.8ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 239.5ms\n",
      "Speed: 3.5ms preprocess, 239.5ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 234.3ms\n",
      "Speed: 2.6ms preprocess, 234.3ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 267.6ms\n",
      "Speed: 4.7ms preprocess, 267.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 277.6ms\n",
      "Speed: 3.9ms preprocess, 277.6ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 271.7ms\n",
      "Speed: 4.0ms preprocess, 271.7ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 289.9ms\n",
      "Speed: 4.0ms preprocess, 289.9ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 258.0ms\n",
      "Speed: 2.9ms preprocess, 258.0ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 269.7ms\n",
      "Speed: 3.0ms preprocess, 269.7ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 274.4ms\n",
      "Speed: 4.1ms preprocess, 274.4ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 265.4ms\n",
      "Speed: 4.0ms preprocess, 265.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 255.1ms\n",
      "Speed: 3.0ms preprocess, 255.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 267.9ms\n",
      "Speed: 4.0ms preprocess, 267.9ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 280.8ms\n",
      "Speed: 4.6ms preprocess, 280.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 228.4ms\n",
      "Speed: 4.4ms preprocess, 228.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 287.8ms\n",
      "Speed: 4.5ms preprocess, 287.8ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 282.8ms\n",
      "Speed: 3.0ms preprocess, 282.8ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 251.8ms\n",
      "Speed: 4.7ms preprocess, 251.8ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 264.4ms\n",
      "Speed: 4.6ms preprocess, 264.4ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 272.7ms\n",
      "Speed: 3.2ms preprocess, 272.7ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 287.9ms\n",
      "Speed: 4.0ms preprocess, 287.9ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 275.7ms\n",
      "Speed: 4.3ms preprocess, 275.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 276.8ms\n",
      "Speed: 2.8ms preprocess, 276.8ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 264.1ms\n",
      "Speed: 2.8ms preprocess, 264.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 234.9ms\n",
      "Speed: 4.5ms preprocess, 234.9ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 230.3ms\n",
      "Speed: 2.9ms preprocess, 230.3ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 265.6ms\n",
      "Speed: 5.8ms preprocess, 265.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 219.1ms\n",
      "Speed: 3.0ms preprocess, 219.1ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 233.1ms\n",
      "Speed: 2.9ms preprocess, 233.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 236.1ms\n",
      "Speed: 3.6ms preprocess, 236.1ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 260.3ms\n",
      "Speed: 5.6ms preprocess, 260.3ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 242.0ms\n",
      "Speed: 3.0ms preprocess, 242.0ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 257.0ms\n",
      "Speed: 2.9ms preprocess, 257.0ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 283.0ms\n",
      "Speed: 3.7ms preprocess, 283.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 255.3ms\n",
      "Speed: 3.4ms preprocess, 255.3ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 237.7ms\n",
      "Speed: 2.5ms preprocess, 237.7ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 226.2ms\n",
      "Speed: 3.1ms preprocess, 226.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 208.3ms\n",
      "Speed: 4.1ms preprocess, 208.3ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 258.1ms\n",
      "Speed: 4.7ms preprocess, 258.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 256.5ms\n",
      "Speed: 4.9ms preprocess, 256.5ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 270.6ms\n",
      "Speed: 3.1ms preprocess, 270.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 249.1ms\n",
      "Speed: 3.4ms preprocess, 249.1ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 256.9ms\n",
      "Speed: 3.9ms preprocess, 256.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 247.7ms\n",
      "Speed: 3.7ms preprocess, 247.7ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 258.9ms\n",
      "Speed: 3.3ms preprocess, 258.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 251.8ms\n",
      "Speed: 4.5ms preprocess, 251.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 235.3ms\n",
      "Speed: 3.1ms preprocess, 235.3ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 240.2ms\n",
      "Speed: 3.0ms preprocess, 240.2ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 237.3ms\n",
      "Speed: 3.6ms preprocess, 237.3ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 235.0ms\n",
      "Speed: 4.6ms preprocess, 235.0ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 168.3ms\n",
      "Speed: 5.7ms preprocess, 168.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 157.0ms\n",
      "Speed: 5.0ms preprocess, 157.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 259.7ms\n",
      "Speed: 3.9ms preprocess, 259.7ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 240.9ms\n",
      "Speed: 3.3ms preprocess, 240.9ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 244.4ms\n",
      "Speed: 2.9ms preprocess, 244.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 244.9ms\n",
      "Speed: 2.1ms preprocess, 244.9ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 243.9ms\n",
      "Speed: 2.6ms preprocess, 243.9ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 192.6ms\n",
      "Speed: 4.0ms preprocess, 192.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 271.1ms\n",
      "Speed: 3.5ms preprocess, 271.1ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 227.3ms\n",
      "Speed: 5.3ms preprocess, 227.3ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 266.3ms\n",
      "Speed: 2.6ms preprocess, 266.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 257.1ms\n",
      "Speed: 2.7ms preprocess, 257.1ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 257.4ms\n",
      "Speed: 4.0ms preprocess, 257.4ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 243.6ms\n",
      "Speed: 3.7ms preprocess, 243.6ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 254.7ms\n",
      "Speed: 4.6ms preprocess, 254.7ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 267.5ms\n",
      "Speed: 3.6ms preprocess, 267.5ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 269.1ms\n",
      "Speed: 3.2ms preprocess, 269.1ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 255.1ms\n",
      "Speed: 3.5ms preprocess, 255.1ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 268.3ms\n",
      "Speed: 4.4ms preprocess, 268.3ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 265.2ms\n",
      "Speed: 3.0ms preprocess, 265.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 280.7ms\n",
      "Speed: 3.0ms preprocess, 280.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 263.3ms\n",
      "Speed: 4.6ms preprocess, 263.3ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 259.3ms\n",
      "Speed: 2.6ms preprocess, 259.3ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 263.9ms\n",
      "Speed: 3.0ms preprocess, 263.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 262.1ms\n",
      "Speed: 5.6ms preprocess, 262.1ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 264.1ms\n",
      "Speed: 3.0ms preprocess, 264.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 260.6ms\n",
      "Speed: 3.6ms preprocess, 260.6ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 268.0ms\n",
      "Speed: 3.6ms preprocess, 268.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 237.7ms\n",
      "Speed: 5.0ms preprocess, 237.7ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 264.3ms\n",
      "Speed: 2.9ms preprocess, 264.3ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 259.3ms\n",
      "Speed: 3.2ms preprocess, 259.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 267.3ms\n",
      "Speed: 3.5ms preprocess, 267.3ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 270.7ms\n",
      "Speed: 3.0ms preprocess, 270.7ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 272.7ms\n",
      "Speed: 4.0ms preprocess, 272.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 265.2ms\n",
      "Speed: 3.0ms preprocess, 265.2ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 258.8ms\n",
      "Speed: 3.5ms preprocess, 258.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 260.9ms\n",
      "Speed: 3.3ms preprocess, 260.9ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 269.9ms\n",
      "Speed: 3.0ms preprocess, 269.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 270.2ms\n",
      "Speed: 5.9ms preprocess, 270.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 265.6ms\n",
      "Speed: 3.1ms preprocess, 265.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 273.9ms\n",
      "Speed: 4.0ms preprocess, 273.9ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 272.2ms\n",
      "Speed: 2.8ms preprocess, 272.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 242.9ms\n",
      "Speed: 3.0ms preprocess, 242.9ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 261.1ms\n",
      "Speed: 3.0ms preprocess, 261.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 261.4ms\n",
      "Speed: 4.1ms preprocess, 261.4ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 275.3ms\n",
      "Speed: 5.0ms preprocess, 275.3ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 273.3ms\n",
      "Speed: 2.9ms preprocess, 273.3ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 286.1ms\n",
      "Speed: 3.9ms preprocess, 286.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 269.5ms\n",
      "Speed: 3.0ms preprocess, 269.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 268.8ms\n",
      "Speed: 3.0ms preprocess, 268.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 268.0ms\n",
      "Speed: 3.0ms preprocess, 268.0ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 259.3ms\n",
      "Speed: 3.0ms preprocess, 259.3ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 246.1ms\n",
      "Speed: 3.0ms preprocess, 246.1ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 226.7ms\n",
      "Speed: 2.9ms preprocess, 226.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 287.9ms\n",
      "Speed: 6.9ms preprocess, 287.9ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 270.7ms\n",
      "Speed: 2.7ms preprocess, 270.7ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 273.7ms\n",
      "Speed: 3.0ms preprocess, 273.7ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 267.7ms\n",
      "Speed: 3.9ms preprocess, 267.7ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 255.2ms\n",
      "Speed: 3.0ms preprocess, 255.2ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 254.2ms\n",
      "Speed: 3.0ms preprocess, 254.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 258.4ms\n",
      "Speed: 3.3ms preprocess, 258.4ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 200.4ms\n",
      "Speed: 4.1ms preprocess, 200.4ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 233.4ms\n",
      "Speed: 3.9ms preprocess, 233.4ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 269.6ms\n",
      "Speed: 3.0ms preprocess, 269.6ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 270.3ms\n",
      "Speed: 4.6ms preprocess, 270.3ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 242.8ms\n",
      "Speed: 3.0ms preprocess, 242.8ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 261.7ms\n",
      "Speed: 3.1ms preprocess, 261.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 251.9ms\n",
      "Speed: 3.0ms preprocess, 251.9ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 283.7ms\n",
      "Speed: 3.0ms preprocess, 283.7ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 264.8ms\n",
      "Speed: 3.0ms preprocess, 264.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 262.5ms\n",
      "Speed: 4.0ms preprocess, 262.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 258.1ms\n",
      "Speed: 3.0ms preprocess, 258.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 260.4ms\n",
      "Speed: 3.0ms preprocess, 260.4ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 226.2ms\n",
      "Speed: 3.0ms preprocess, 226.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 268.1ms\n",
      "Speed: 5.1ms preprocess, 268.1ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 281.6ms\n",
      "Speed: 2.0ms preprocess, 281.6ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 253.7ms\n",
      "Speed: 3.0ms preprocess, 253.7ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 266.8ms\n",
      "Speed: 4.0ms preprocess, 266.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 269.9ms\n",
      "Speed: 3.9ms preprocess, 269.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 267.9ms\n",
      "Speed: 3.0ms preprocess, 267.9ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 265.9ms\n",
      "Speed: 4.2ms preprocess, 265.9ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 252.8ms\n",
      "Speed: 4.9ms preprocess, 252.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 261.9ms\n",
      "Speed: 3.9ms preprocess, 261.9ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 272.1ms\n",
      "Speed: 4.0ms preprocess, 272.1ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 272.2ms\n",
      "Speed: 5.0ms preprocess, 272.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 241.3ms\n",
      "Speed: 3.0ms preprocess, 241.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 261.8ms\n",
      "Speed: 3.0ms preprocess, 261.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 218.9ms\n",
      "Speed: 3.1ms preprocess, 218.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 247.7ms\n",
      "Speed: 3.0ms preprocess, 247.7ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 236.3ms\n",
      "Speed: 3.6ms preprocess, 236.3ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 241.5ms\n",
      "Speed: 3.9ms preprocess, 241.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 249.4ms\n",
      "Speed: 5.2ms preprocess, 249.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 240.4ms\n",
      "Speed: 3.2ms preprocess, 240.4ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 239.9ms\n",
      "Speed: 3.0ms preprocess, 239.9ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 1 person, 240.4ms\n",
      "Speed: 3.5ms preprocess, 240.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 212.7ms\n",
      "Speed: 4.0ms preprocess, 212.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 218.6ms\n",
      "Speed: 3.1ms preprocess, 218.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 267.0ms\n",
      "Speed: 3.0ms preprocess, 267.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 222.9ms\n",
      "Speed: 2.9ms preprocess, 222.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 224.3ms\n",
      "Speed: 4.0ms preprocess, 224.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 160.7ms\n",
      "Speed: 4.5ms preprocess, 160.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 239.9ms\n",
      "Speed: 2.0ms preprocess, 239.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 251.9ms\n",
      "Speed: 2.1ms preprocess, 251.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 252.7ms\n",
      "Speed: 4.0ms preprocess, 252.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 252.6ms\n",
      "Speed: 3.3ms preprocess, 252.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 264.3ms\n",
      "Speed: 2.9ms preprocess, 264.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 260.6ms\n",
      "Speed: 2.9ms preprocess, 260.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 247.1ms\n",
      "Speed: 4.0ms preprocess, 247.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 253.8ms\n",
      "Speed: 3.0ms preprocess, 253.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 249.3ms\n",
      "Speed: 3.9ms preprocess, 249.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 198.4ms\n",
      "Speed: 3.0ms preprocess, 198.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.7ms\n",
      "Speed: 4.0ms preprocess, 112.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 220.1ms\n",
      "Speed: 3.0ms preprocess, 220.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 189.5ms\n",
      "Speed: 2.0ms preprocess, 189.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 249.6ms\n",
      "Speed: 3.0ms preprocess, 249.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 250.1ms\n",
      "Speed: 3.0ms preprocess, 250.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 228.9ms\n",
      "Speed: 3.5ms preprocess, 228.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 245.1ms\n",
      "Speed: 3.1ms preprocess, 245.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 247.4ms\n",
      "Speed: 2.3ms preprocess, 247.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 239.0ms\n",
      "Speed: 3.8ms preprocess, 239.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 221.0ms\n",
      "Speed: 4.5ms preprocess, 221.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 249.9ms\n",
      "Speed: 4.0ms preprocess, 249.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 263.8ms\n",
      "Speed: 4.1ms preprocess, 263.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 246.3ms\n",
      "Speed: 2.0ms preprocess, 246.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 251.4ms\n",
      "Speed: 3.6ms preprocess, 251.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 248.5ms\n",
      "Speed: 2.1ms preprocess, 248.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 189.9ms\n",
      "Speed: 3.0ms preprocess, 189.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 241.1ms\n",
      "Speed: 3.6ms preprocess, 241.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 240.1ms\n",
      "Speed: 4.4ms preprocess, 240.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 212.7ms\n",
      "Speed: 3.0ms preprocess, 212.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 247.0ms\n",
      "Speed: 3.0ms preprocess, 247.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 245.7ms\n",
      "Speed: 4.0ms preprocess, 245.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 253.0ms\n",
      "Speed: 5.0ms preprocess, 253.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 239.5ms\n",
      "Speed: 3.0ms preprocess, 239.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 230.6ms\n",
      "Speed: 3.0ms preprocess, 230.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 250.2ms\n",
      "Speed: 4.0ms preprocess, 250.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 248.6ms\n",
      "Speed: 5.0ms preprocess, 248.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 265.3ms\n",
      "Speed: 3.0ms preprocess, 265.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 237.2ms\n",
      "Speed: 3.3ms preprocess, 237.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 251.3ms\n",
      "Speed: 4.0ms preprocess, 251.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 263.2ms\n",
      "Speed: 6.1ms preprocess, 263.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 270.4ms\n",
      "Speed: 3.0ms preprocess, 270.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 237.7ms\n",
      "Speed: 2.1ms preprocess, 237.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 251.3ms\n",
      "Speed: 5.5ms preprocess, 251.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 260.4ms\n",
      "Speed: 4.3ms preprocess, 260.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 257.2ms\n",
      "Speed: 2.8ms preprocess, 257.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 249.3ms\n",
      "Speed: 2.9ms preprocess, 249.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 254.0ms\n",
      "Speed: 5.7ms preprocess, 254.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 156.2ms\n",
      "Speed: 2.0ms preprocess, 156.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 189.9ms\n",
      "Speed: 2.0ms preprocess, 189.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 249.3ms\n",
      "Speed: 2.9ms preprocess, 249.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 256.6ms\n",
      "Speed: 5.0ms preprocess, 256.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 190.7ms\n",
      "Speed: 3.0ms preprocess, 190.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 261.0ms\n",
      "Speed: 4.1ms preprocess, 261.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 212.6ms\n",
      "Speed: 2.0ms preprocess, 212.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 256.6ms\n",
      "Speed: 3.6ms preprocess, 256.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 247.4ms\n",
      "Speed: 3.0ms preprocess, 247.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 258.3ms\n",
      "Speed: 3.0ms preprocess, 258.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 251.1ms\n",
      "Speed: 2.0ms preprocess, 251.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 259.6ms\n",
      "Speed: 5.3ms preprocess, 259.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 261.5ms\n",
      "Speed: 3.0ms preprocess, 261.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 254.6ms\n",
      "Speed: 2.1ms preprocess, 254.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 250.4ms\n",
      "Speed: 4.0ms preprocess, 250.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 258.7ms\n",
      "Speed: 3.9ms preprocess, 258.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 262.6ms\n",
      "Speed: 3.1ms preprocess, 262.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 215.6ms\n",
      "Speed: 3.0ms preprocess, 215.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 234.0ms\n",
      "Speed: 4.9ms preprocess, 234.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 189.6ms\n",
      "Speed: 3.0ms preprocess, 189.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 239.5ms\n",
      "Speed: 4.0ms preprocess, 239.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 256.6ms\n",
      "Speed: 5.0ms preprocess, 256.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 183.0ms\n",
      "Speed: 5.0ms preprocess, 183.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 105.2ms\n",
      "Speed: 2.0ms preprocess, 105.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 100.7ms\n",
      "Speed: 2.0ms preprocess, 100.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.2ms\n",
      "Speed: 1.1ms preprocess, 114.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 108.7ms\n",
      "Speed: 1.0ms preprocess, 108.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 109.9ms\n",
      "Speed: 2.0ms preprocess, 109.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.1ms\n",
      "Speed: 2.0ms preprocess, 115.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.6ms\n",
      "Speed: 3.0ms preprocess, 96.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 155.0ms\n",
      "Speed: 1.0ms preprocess, 155.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.0ms\n",
      "Speed: 1.8ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 94.0ms\n",
      "Speed: 1.6ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 117.0ms\n",
      "Speed: 3.0ms preprocess, 117.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.7ms\n",
      "Speed: 3.0ms preprocess, 93.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 95.4ms\n",
      "Speed: 2.0ms preprocess, 95.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 178.2ms\n",
      "Speed: 2.0ms preprocess, 178.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 274.1ms\n",
      "Speed: 7.4ms preprocess, 274.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.2ms\n",
      "Speed: 4.0ms preprocess, 321.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 283.7ms\n",
      "Speed: 6.0ms preprocess, 283.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 850.3ms\n",
      "Speed: 8.6ms preprocess, 850.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 337.5ms\n",
      "Speed: 6.0ms preprocess, 337.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 355.6ms\n",
      "Speed: 7.7ms preprocess, 355.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 649.2ms\n",
      "Speed: 3.0ms preprocess, 649.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 609.1ms\n",
      "Speed: 7.4ms preprocess, 609.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 443.8ms\n",
      "Speed: 6.6ms preprocess, 443.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 378.4ms\n",
      "Speed: 5.1ms preprocess, 378.4ms inference, 83.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 658.9ms\n",
      "Speed: 89.2ms preprocess, 658.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 262.9ms\n",
      "Speed: 5.6ms preprocess, 262.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 264.9ms\n",
      "Speed: 5.0ms preprocess, 264.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 256.4ms\n",
      "Speed: 3.4ms preprocess, 256.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 223.1ms\n",
      "Speed: 5.9ms preprocess, 223.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 256.3ms\n",
      "Speed: 3.0ms preprocess, 256.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 260.1ms\n",
      "Speed: 3.5ms preprocess, 260.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 317.3ms\n",
      "Speed: 3.4ms preprocess, 317.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 333.1ms\n",
      "Speed: 6.3ms preprocess, 333.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 937.6ms\n",
      "Speed: 11.4ms preprocess, 937.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 257.0ms\n",
      "Speed: 5.0ms preprocess, 257.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 251.7ms\n",
      "Speed: 5.0ms preprocess, 251.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 252.2ms\n",
      "Speed: 2.9ms preprocess, 252.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 262.8ms\n",
      "Speed: 5.3ms preprocess, 262.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 239.6ms\n",
      "Speed: 3.0ms preprocess, 239.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 248.0ms\n",
      "Speed: 3.6ms preprocess, 248.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 106.8ms\n",
      "Speed: 2.0ms preprocess, 106.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 120.0ms\n",
      "Speed: 3.0ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 96.2ms\n",
      "Speed: 1.5ms preprocess, 96.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 182.9ms\n",
      "Speed: 1.0ms preprocess, 182.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 220.6ms\n",
      "Speed: 3.7ms preprocess, 220.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 236.0ms\n",
      "Speed: 4.0ms preprocess, 236.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 253.9ms\n",
      "Speed: 6.0ms preprocess, 253.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 248.8ms\n",
      "Speed: 3.9ms preprocess, 248.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 258.1ms\n",
      "Speed: 2.0ms preprocess, 258.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 259.3ms\n",
      "Speed: 6.1ms preprocess, 259.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 273.5ms\n",
      "Speed: 5.0ms preprocess, 273.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 273.2ms\n",
      "Speed: 4.0ms preprocess, 273.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 283.8ms\n",
      "Speed: 3.9ms preprocess, 283.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 217.6ms\n",
      "Speed: 3.1ms preprocess, 217.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 240.4ms\n",
      "Speed: 3.5ms preprocess, 240.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 240.0ms\n",
      "Speed: 3.0ms preprocess, 240.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 264.7ms\n",
      "Speed: 6.9ms preprocess, 264.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 130.6ms\n",
      "Speed: 2.1ms preprocess, 130.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.9ms\n",
      "Speed: 2.0ms preprocess, 110.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 136.1ms\n",
      "Speed: 2.0ms preprocess, 136.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 111.2ms\n",
      "Speed: 1.5ms preprocess, 111.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.3ms\n",
      "Speed: 3.2ms preprocess, 103.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 109.8ms\n",
      "Speed: 3.0ms preprocess, 109.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.5ms\n",
      "Speed: 2.0ms preprocess, 107.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.8ms\n",
      "Speed: 1.2ms preprocess, 99.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.5ms\n",
      "Speed: 2.0ms preprocess, 121.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 224.0ms\n",
      "Speed: 5.5ms preprocess, 224.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 306.8ms\n",
      "Speed: 3.0ms preprocess, 306.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 417.3ms\n",
      "Speed: 2.0ms preprocess, 417.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 269.3ms\n",
      "Speed: 5.0ms preprocess, 269.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.1ms\n",
      "Speed: 4.5ms preprocess, 311.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 283.6ms\n",
      "Speed: 6.8ms preprocess, 283.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 702.9ms\n",
      "Speed: 5.6ms preprocess, 702.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed dataset saved in 'archive/processed_RWF-2000' directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# Initialize YOLO model\n",
    "model = YOLO(pose_model_path)  # Replace with your YOLO model path\n",
    "\n",
    "# Define dataset paths\n",
    "input_root_dir = 'archive/RWF-2000'  # Original dataset directory\n",
    "output_root_dir = 'archive/processed_RWF-2000'  # Directory to save processed dataset\n",
    "\n",
    "# Define categories and subcategories\n",
    "sets = ['train', 'val']\n",
    "categories = ['Fight', 'NonFight']\n",
    "\n",
    "# Number of videos to process per category\n",
    "video_limit = 3\n",
    "\n",
    "# Loop through each set and category\n",
    "for set_name in sets:\n",
    "    for category in categories:\n",
    "        input_dir = os.path.join(input_root_dir, set_name, category)\n",
    "        output_dir = os.path.join(output_root_dir, set_name, category)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Loop through videos in the current category\n",
    "        processed_videos = 0\n",
    "        for video_file in os.listdir(input_dir):\n",
    "            if video_file.endswith('.avi') and processed_videos < video_limit:  # Process only .avi files and limit to `video_limit`\n",
    "                video_name = os.path.splitext(video_file)[0]\n",
    "                video_input_path = os.path.join(input_dir, video_file)\n",
    "\n",
    "                # Create a subfolder for each video in the output directory\n",
    "                video_output_dir = os.path.join(output_dir, video_name)\n",
    "                os.makedirs(video_output_dir, exist_ok=True)\n",
    "\n",
    "                # Paths for saving original and processed videos, and keypoints\n",
    "                original_video_path = os.path.join(video_output_dir, 'original.avi')\n",
    "                processed_video_path = os.path.join(video_output_dir, 'processed.avi')\n",
    "                keypoints_path = os.path.join(video_output_dir, 'keypoints.jsonl')\n",
    "\n",
    "                # Open the input video\n",
    "                cap = cv2.VideoCapture(video_input_path)\n",
    "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "                # Set up video writers for original and processed videos\n",
    "                out_original = cv2.VideoWriter(original_video_path, cv2.VideoWriter_fourcc(*'XVID'), fps, (width, height))\n",
    "                out_processed = cv2.VideoWriter(processed_video_path, cv2.VideoWriter_fourcc(*'XVID'), fps, (width, height))\n",
    "\n",
    "                # Open keypoints file for writing\n",
    "                with open(keypoints_path, 'w') as kp_file:\n",
    "                    frame_idx = 0\n",
    "                    while cap.isOpened():\n",
    "                        ret, frame = cap.read()\n",
    "                        if not ret:\n",
    "                            break\n",
    "\n",
    "                        # Save the original frame\n",
    "                        out_original.write(frame)\n",
    "\n",
    "                        # Run YOLO model to get keypoints and process the frame\n",
    "                        results = model(frame)\n",
    "                        keypoints_data = []\n",
    "                        \n",
    "                        # Extract keypoints and confidence if available\n",
    "                        if results[0].keypoints:\n",
    "                            for kp in results[0].keypoints.data:\n",
    "                                xy = kp[:,:2].tolist()  # get x,y coordinates\n",
    "                                conf = kp[:,2].tolist() if kp.shape[1] > 2 else None  # get confidence if available\n",
    "                                keypoints_data.append({\n",
    "                                    \"coordinates\": xy,\n",
    "                                    \"confidence\": conf\n",
    "                                })\n",
    "\n",
    "                        # Save keypoints for this frame to JSONL file\n",
    "                        json.dump({\"frame\": frame_idx, \"keypoints\": keypoints_data}, kp_file)\n",
    "                        kp_file.write('\\n')\n",
    "\n",
    "                        # Draw keypoints on frame and save to processed video\n",
    "                        frame_with_keypoints = results[0].plot()\n",
    "                        out_processed.write(frame_with_keypoints)\n",
    "\n",
    "                        frame_idx += 1\n",
    "\n",
    "                # Release resources\n",
    "                cap.release()\n",
    "                out_original.release()\n",
    "                out_processed.release()\n",
    "\n",
    "                # Increment the counter for processed videos\n",
    "                processed_videos += 1\n",
    "                if processed_videos >= video_limit:\n",
    "                    break  # Stop once we've processed the limit for this category\n",
    "\n",
    "print(f\"Processed dataset saved in '{output_root_dir}' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# Initialize YOLO model\n",
    "model = YOLO(\"yolov8_model_path.pt\")  # Replace with your YOLO model path\n",
    "\n",
    "# Define dataset paths\n",
    "input_root_dir = 'archive/RWF-2000'  # Original dataset directory\n",
    "output_root_dir = 'archive/processed_RWF-2000'  # Directory to save processed dataset\n",
    "\n",
    "# Define categories and subcategories\n",
    "sets = ['train', 'val']\n",
    "categories = ['Fight', 'NonFight']\n",
    "\n",
    "# Loop through each set and category\n",
    "for set_name in sets:\n",
    "    for category in categories:\n",
    "        input_dir = os.path.join(input_root_dir, set_name, category)\n",
    "        output_dir = os.path.join(output_root_dir, set_name, category)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Loop through videos in the current category\n",
    "        for video_file in os.listdir(input_dir):\n",
    "            if video_file.endswith('.avi'):  # Process only .avi files\n",
    "                video_name = os.path.splitext(video_file)[0]\n",
    "                video_input_path = os.path.join(input_dir, video_file)\n",
    "\n",
    "                # Create a subfolder for each video in the output directory\n",
    "                video_output_dir = os.path.join(output_dir, video_name)\n",
    "                os.makedirs(video_output_dir, exist_ok=True)\n",
    "\n",
    "                # Paths for saving original and processed videos, and keypoints\n",
    "                original_video_path = os.path.join(video_output_dir, 'original.avi')\n",
    "                processed_video_path = os.path.join(video_output_dir, 'processed.avi')\n",
    "                keypoints_path = os.path.join(video_output_dir, 'keypoints.jsonl')\n",
    "\n",
    "                # Open the input video\n",
    "                cap = cv2.VideoCapture(video_input_path)\n",
    "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "                # Set up video writers for original and processed videos\n",
    "                out_original = cv2.VideoWriter(original_video_path, cv2.VideoWriter_fourcc(*'XVID'), fps, (width, height))\n",
    "                out_processed = cv2.VideoWriter(processed_video_path, cv2.VideoWriter_fourcc(*'XVID'), fps, (width, height))\n",
    "\n",
    "                # Open keypoints file for writing\n",
    "                with open(keypoints_path, 'w') as kp_file:\n",
    "                    frame_idx = 0\n",
    "                    while cap.isOpened():\n",
    "                        ret, frame = cap.read()\n",
    "                        if not ret:\n",
    "                            break\n",
    "\n",
    "                        # Save the original frame\n",
    "                        out_original.write(frame)\n",
    "\n",
    "                        # Run YOLO model to get keypoints and process the frame\n",
    "                        results = model(frame)\n",
    "                        keypoints = results[0].keypoints.cpu().numpy().tolist()  # Convert keypoints to list\n",
    "\n",
    "                        # Save keypoints for this frame to JSONL file\n",
    "                        json.dump({\"frame\": frame_idx, \"keypoints\": keypoints}, kp_file)\n",
    "                        kp_file.write('\\n')\n",
    "\n",
    "                        # Draw keypoints on frame and save to processed video\n",
    "                        frame_with_keypoints = results[0].plot()\n",
    "                        out_processed.write(frame_with_keypoints)\n",
    "\n",
    "                        frame_idx += 1\n",
    "\n",
    "                # Release resources\n",
    "                cap.release()\n",
    "                out_original.release()\n",
    "                out_processed.release()\n",
    "\n",
    "print(f\"Processed dataset saved in '{output_root_dir}' directory.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
