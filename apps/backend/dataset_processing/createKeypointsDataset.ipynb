{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics tqdm numpy opencv-python datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_working_directory = os.getcwd()\n",
    "\n",
    "YOLO_path = os.path.join(current_working_directory, \"models/yolov8n-pose.pt\") #path to the YOLO model\n",
    "datasetDir = os.path.join(current_working_directory, \"archive\", \"RWF-2000\") #change here to the other dataset like RFC-2000\n",
    "newKeypointsDir = os.path.join(current_working_directory, \"archive\", \"Keypoints_Dataset\") #The new json data are saved here\n",
    "os.makedirs(newKeypointsDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options for saving\n",
    "save_original = False  # Set to True if you want to save the original video\n",
    "save_processed = False  # Set to True if you want to save the processed video with keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = YOLO(YOLO_path) #staring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset categories and video processing limits\n",
    "sets = ['train', 'val']\n",
    "categories = ['Fight', 'NonFight']\n",
    "video_limit = 10  # Limit number of videos processed per category\n",
    "\n",
    "#making the labels in the COCO format for YOLO model\n",
    "labeledKeypoints = [\n",
    "    \"nose\", \"left_eye\", \"right_eye\", \"left_ear\", \"right_ear\", \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\", \"left_wrist\", \"right_wrist\", \"left_hip\", \"right_hip\", \"left_knee\", \"right_knee\", \"left_ankle\", \"right_ankle\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixFileName(filename):\n",
    "    fixedName = re.sub(r'[^A-Za-z0-9_]', '', filename)\n",
    "    \n",
    "    # If the sanitized name is too short or empty, create a random name\n",
    "    if len(fixedName) < 5:\n",
    "        fixedName = ''.join(random.choices(string.ascii_letters + string.digits, k=8))\n",
    "    \n",
    "    return fixedName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each set (train/val) and category (Fight/NonFight)\n",
    "for set_name in tqdm(sets, desc=\"Processing Sets\"):\n",
    "    for category in tqdm(categories, desc=f\"Processing Categories in {set_name}\", leave=False):\n",
    "        input_dir = os.path.join(datasetDir, set_name, category)\n",
    "        video_count = 0\n",
    "\n",
    "        for video_file in tqdm(os.listdir(input_dir), desc=f\"Processing Videos in {category}\", leave=False):\n",
    "            if not video_file.endswith(('.avi', '.mp4')):\n",
    "                continue\n",
    "            \n",
    "            ## uncomment the code below to apply the video limit\n",
    "            # if video_count >= video_limit:\n",
    "            #     break\n",
    "\n",
    "            # Sanitize or generate a unique name for problematic video filenames\n",
    "            videoName = fixFileName(os.path.splitext(video_file)[0])\n",
    "            videoDirectory = os.path.join(newKeypointsDir, set_name, category, f\"{videoName}\")\n",
    "            os.makedirs(videoDirectory, exist_ok=True)\n",
    "\n",
    "            videoPath = os.path.join(input_dir, video_file)\n",
    "            json_output_path = os.path.join(videoDirectory, f\"{videoName}.json\")\n",
    "\n",
    "            # Copy original video if save_original is True\n",
    "            if save_original:\n",
    "                original_save_path = os.path.join(videoDirectory, f\"{videoName}.avi\")\n",
    "                try:\n",
    "                    shutil.copy2(videoPath, original_save_path)\n",
    "                    logging.info(f\"Original video saved: {original_save_path}\")\n",
    "                except FileNotFoundError as e:\n",
    "                    logging.warning(f\"File not found or accessible: {videoPath}. Skipping this file.\")\n",
    "                    continue\n",
    "\n",
    "            # making the video capture ready for getting frames\n",
    "            videoCap = cv2.VideoCapture(videoPath)\n",
    "            frame_index = 0\n",
    "            keyPointsData = []\n",
    "\n",
    "            # Set up writer for processed video if save_processed is True\n",
    "            if save_processed:\n",
    "                processedVideoP = os.path.join(videoDirectory, f\"{videoName}_processed.avi\")\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "                fps = videoCap.get(cv2.CAP_PROP_FPS) #frames for the video\n",
    "                frameWidth = int(videoCap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                frameHeight = int(videoCap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                processedVideoWriter = cv2.VideoWriter(processedVideoP, fourcc, fps, (frameWidth, frameHeight))\n",
    "                logging.info(f\"Writer initialized for: {processedVideoP}\")\n",
    "\n",
    "            # Process each frame\n",
    "            while videoCap.isOpened():\n",
    "                ret, frame = videoCap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                # Detect keypoints using YOLO model\n",
    "                results = model(frame)\n",
    "                newFrameData = []\n",
    "\n",
    "                # Extract keypoints and bounding box data for JSON output\n",
    "                for result in results:\n",
    "                    boxes = result.boxes\n",
    "                    keypoints = result.keypoints\n",
    "\n",
    "                    if boxes is not None and len(boxes) > 0:\n",
    "                        for i in range(len(boxes)):\n",
    "                            box_data = boxes.xyxy[i].cpu().numpy()\n",
    "                            confidence = boxes.conf[i].cpu().item()\n",
    "                            box = {\n",
    "                                \"x1\": float(box_data[0]),\n",
    "                                \"y1\": float(box_data[1]),\n",
    "                                \"x2\": float(box_data[2]),\n",
    "                                \"y2\": float(box_data[3])\n",
    "                            }\n",
    "\n",
    "                            keypoints_data = []\n",
    "                            if keypoints is not None:\n",
    "                                keypoints_array = keypoints.data[i].cpu().numpy()\n",
    "                                for j, (x, y, conf) in enumerate(keypoints_array):\n",
    "                                    keypoints_data.append({\n",
    "                                        \"label\": labeledKeypoints[j],\n",
    "                                        \"coordinates\": {\"x\": float(x), \"y\": float(y)},\n",
    "                                        \"confidence\": float(conf)\n",
    "                                    })\n",
    "\n",
    "                            newFrameData.append({\n",
    "                                \"person_id\": i + 1,\n",
    "                                \"confidence\": confidence,\n",
    "                                \"box\": box,\n",
    "                                \"keypoints\": keypoints_data\n",
    "                            })\n",
    "\n",
    "                keyPointsData.append({\"frame\": frame_index, \"detections\": newFrameData})\n",
    "\n",
    "                # Use results[0].plot() for processed video frame\n",
    "                if save_processed:\n",
    "                    frame_with_keypoints = results[0].plot()\n",
    "                    processedVideoWriter.write(frame_with_keypoints)\n",
    "\n",
    "                frame_index += 1\n",
    "\n",
    "            # Release resources\n",
    "            videoCap.release()\n",
    "            if save_processed:\n",
    "                processedVideoWriter.release()\n",
    "                logging.info(f\"Processed video saved to: {processedVideoP}\")\n",
    "                \n",
    "            # Save JSON data for keypoints\n",
    "            with open(json_output_path, 'w') as json_file:\n",
    "                json.dump(keyPointsData, json_file, indent=4)\n",
    "                logging.info(f\"Keypoints data saved to: {json_output_path}\")\n",
    "\n",
    "            video_count += 1\n",
    "\n",
    "print(\"Done\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
