{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow mediapipe h5py scipy scikit-learn matplotlib numpy pandas protobuf tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "root_dir = os.path.join(os.path.dirname(os.getcwd()), \"dataset_processing\", \"archive\", \"processed_RWF-2000\")\n",
    "no_of_timesteps = 20\n",
    "keypoint_labels = [\n",
    "    \"nose\", \"left_eye\", \"right_eye\", \"left_ear\", \"right_ear\",\n",
    "    \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\",\n",
    "    \"left_wrist\", \"right_wrist\", \"left_hip\", \"right_hip\",\n",
    "    \"left_knee\", \"right_knee\", \"left_ankle\", \"right_ankle\"\n",
    "]\n",
    "\n",
    "# Initialize dataset lists\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback for live plotting\n",
    "class LivePlotCallback(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "        plt.ion()  # Enable interactive mode\n",
    "        self.fig, self.ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        self.ax[0].set_title(\"Loss\")\n",
    "        self.ax[1].set_title(\"Accuracy\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        self.accuracies.append(logs[\"accuracy\"])\n",
    "        \n",
    "        # Clear and update loss plot\n",
    "        self.ax[0].cla()\n",
    "        self.ax[0].plot(self.losses, label=\"Training Loss\", color=\"blue\")\n",
    "        self.ax[0].set_title(\"Loss\")\n",
    "        self.ax[0].legend()\n",
    "\n",
    "        # Clear and update accuracy plot\n",
    "        self.ax[1].cla()\n",
    "        self.ax[1].plot(self.accuracies, label=\"Training Accuracy\", color=\"green\")\n",
    "        self.ax[1].set_title(\"Accuracy\")\n",
    "        self.ax[1].legend()\n",
    "        \n",
    "        plt.pause(0.01)  # Small pause to update the plot\n",
    "        plt.draw()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        plt.ioff()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_data(json_path, label):\n",
    "    try:\n",
    "        with open(json_path) as file:\n",
    "            data = json.load(file)\n",
    "            frames_data = []\n",
    "\n",
    "            if len(data) < no_of_timesteps:\n",
    "                logging.warning(f\"Skipping {json_path} as it has fewer than {no_of_timesteps} frames.\")\n",
    "                return None\n",
    "\n",
    "            for i in range(no_of_timesteps, len(data)):\n",
    "                sequence = []\n",
    "                frames = data[i - no_of_timesteps:i]\n",
    "\n",
    "                for frame in frames:\n",
    "                    if frame[\"detections\"]:\n",
    "                        person = frame[\"detections\"][0]\n",
    "                        person_keypoints = []\n",
    "                        \n",
    "                        keypoints_dict = {kp['label']: kp['coordinates'] for kp in person['keypoints']}\n",
    "                        \n",
    "                        for label in keypoint_labels:\n",
    "                            if label in keypoints_dict:\n",
    "                                coords = keypoints_dict[label]\n",
    "                                person_keypoints.extend([coords['x'], coords['y']])\n",
    "                            else:\n",
    "                                person_keypoints.extend([0.0, 0.0])\n",
    "                    else:\n",
    "                        person_keypoints = [0.0, 0.0] * len(keypoint_labels)\n",
    "                    \n",
    "                    sequence.append(person_keypoints)\n",
    "\n",
    "                frames_data.append(np.array(sequence))\n",
    "\n",
    "            return frames_data\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading {json_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(root_dir):\n",
    "    global X, y\n",
    "    for category in ['train', 'val']:\n",
    "        for label in ['Fight', 'NonFight']:\n",
    "            category_dir = os.path.join(root_dir, category, label)\n",
    "            logging.info(f\"Processing category '{label}' in '{category}' set...\")\n",
    "\n",
    "            for video_folder in tqdm(os.listdir(category_dir)):\n",
    "                video_folder_path = os.path.join(category_dir, video_folder)\n",
    "\n",
    "                if os.path.isdir(video_folder_path):\n",
    "                    json_path = os.path.join(video_folder_path, f\"{video_folder}.json\")\n",
    "\n",
    "                    if os.path.isfile(json_path):\n",
    "                        sequences = load_json_data(json_path, label)\n",
    "\n",
    "                        if sequences:\n",
    "                            X.extend(sequences)\n",
    "                            y.extend([1 if label == 'Fight' else 0] * len(sequences))\n",
    "\n",
    "\n",
    "# Load and process dataset\n",
    "process_dataset(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays with correct shape\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.int32)\n",
    "\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "if len(X) == 0:\n",
    "    raise ValueError(\"No data was loaded. Check the dataset directory and file paths.\")\n",
    "\n",
    "# Normalize the coordinates\n",
    "mean = np.mean(X.reshape(-1, X.shape[-1]), axis=0)\n",
    "std = np.std(X.reshape(-1, X.shape[-1]), axis=0)\n",
    "std = np.where(std == 0, 1, std)\n",
    "X = (X - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nTraining set shapes:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(no_of_timesteps, len(keypoint_labels) * 2), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6455/6455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8772 - loss: 0.2934"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6455/6455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 21ms/step - accuracy: 0.8772 - loss: 0.2934 - val_accuracy: 0.8903 - val_loss: 0.2623\n",
      "Epoch 5/50\n",
      "\u001b[1m2109/6455\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 19ms/step - accuracy: 0.8901 - loss: 0.2619"
     ]
    }
   ],
   "source": [
    "# Train the model with the LivePlotCallback\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[LivePlotCallback()])\n",
    "\n",
    "model.save(\"lstm-violence-detection.h5\")\n",
    "\n",
    "# Print final metrics \n",
    "final_loss, final_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nFinal Test Accuracy: {final_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
